#!/usr/bin/env python3
"""
æµ‹è¯•åŒå®ä¾‹é…ç½®ç®¡ç† - æŒä¹…å®¢æˆ·ç«¯ç‰ˆæœ¬
ä½¿ç”¨æŒä¹…çš„ SimpleClient å®ä¾‹ï¼Œé¿å…æ¯æ¬¡æµ‹è¯•éƒ½é‡æ–°åˆ›å»ºè¿æ¥
"""

import asyncio
import sys
import os
from mcp_framework.client.simple import SimpleClient


class PersistentClientTester:
    def __init__(self, server_script: str):
        self.server_script = server_script
        self.clients = {}  # å­˜å‚¨æŒä¹…çš„å®¢æˆ·ç«¯å®ä¾‹
        self.config_dir = "/Users/lilei/project/config/test_mcp_server_config"
        
    async def setup_clients(self):
        """åˆå§‹åŒ–æŒä¹…çš„å®¢æˆ·ç«¯å®ä¾‹"""
        print("ğŸ”§ åˆå§‹åŒ–æŒä¹…å®¢æˆ·ç«¯å®ä¾‹...")
        
        aliases = ["test_no_config", "test_with_config"]
        
        for alias in aliases:
            try:
                print(f"   åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹: {alias}")
                client = SimpleClient(
                    self.server_script, 
                    alias=alias, 
                    config_dir=self.config_dir
                )
                await client.__aenter__()  # æ‰‹åŠ¨è¿›å…¥å¼‚æ­¥ä¸Šä¸‹æ–‡
                self.clients[alias] = client
                print(f"   âœ… å®¢æˆ·ç«¯ '{alias}' åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                print(f"   âŒ å®¢æˆ·ç«¯ '{alias}' åˆ›å»ºå¤±è´¥: {e}")
                raise
        
        print(f"âœ… æ‰€æœ‰å®¢æˆ·ç«¯å®ä¾‹åˆ›å»ºå®Œæˆ: {list(self.clients.keys())}")
    
    async def cleanup_clients(self):
        """æ¸…ç†æ‰€æœ‰å®¢æˆ·ç«¯å®ä¾‹"""
        print("ğŸ§¹ æ¸…ç†å®¢æˆ·ç«¯å®ä¾‹...")
        
        for alias, client in self.clients.items():
            try:
                await client.__aexit__(None, None, None)  # æ‰‹åŠ¨é€€å‡ºå¼‚æ­¥ä¸Šä¸‹æ–‡
                print(f"   âœ… å®¢æˆ·ç«¯ '{alias}' æ¸…ç†å®Œæˆ")
            except Exception as e:
                print(f"   âš ï¸  å®¢æˆ·ç«¯ '{alias}' æ¸…ç†æ—¶å‡ºé”™: {e}")
        
        self.clients.clear()
        print("âœ… æ‰€æœ‰å®¢æˆ·ç«¯å®ä¾‹å·²æ¸…ç†")
    
    def get_client(self, alias: str):
        """è·å–æŒ‡å®šåˆ«åçš„å®¢æˆ·ç«¯å®ä¾‹"""
        if alias not in self.clients:
            raise ValueError(f"å®¢æˆ·ç«¯å®ä¾‹ '{alias}' ä¸å­˜åœ¨")
        return self.clients[alias]
    
    async def test_instance_with_alias(self, alias: str):
        """æµ‹è¯•æŒ‡å®šåˆ«åçš„å®ä¾‹ - ä½¿ç”¨æŒä¹…å®¢æˆ·ç«¯"""
        print(f"\nğŸ§ª æµ‹è¯•å®ä¾‹ '{alias}' (æŒä¹…å®¢æˆ·ç«¯)...")
        
        try:
            client = self.get_client(alias)
            print(f"âœ… ä½¿ç”¨ç°æœ‰å®¢æˆ·ç«¯å®ä¾‹ '{alias}'")
            
            # è·å–å·¥å…·åˆ—è¡¨
            tools = await client.tools()
            print(f"   å¯ç”¨å·¥å…·æ•°é‡: {len(tools)}")
            
            # éªŒè¯ query_expert_stream å·¥å…·å­˜åœ¨
            has_expert_tool = await client.has_tool("query_expert_stream")
            if not has_expert_tool:
                print(f"âŒ å®ä¾‹ '{alias}' ç¼ºå°‘ query_expert_stream å·¥å…·")
                return False
            
            print(f"âœ… å®ä¾‹ '{alias}' åŒ…å« query_expert_stream å·¥å…·")
            
            # æµ‹è¯•ä¸“å®¶æŸ¥è¯¢
            print(f"   æµ‹è¯•ä¸“å®¶æŸ¥è¯¢...")
            
            try:
                result = await client.call("query_expert_stream",
                    question=f"è¿™æ˜¯æ¥è‡ªæŒä¹…å®ä¾‹ {alias} çš„æµ‹è¯•æŸ¥è¯¢ï¼Œè¯·ç®€å•å›å¤ç¡®è®¤æ”¶åˆ°ã€‚"
                )
                print(f"   âœ… ä¸“å®¶æŸ¥è¯¢æˆåŠŸ")
                response_preview = str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
                print(f"   å“åº”é¢„è§ˆ: {response_preview}")
            except Exception as e:
                print(f"   âŒ ä¸“å®¶æŸ¥è¯¢å¤±è´¥: {e}")
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å®ä¾‹ '{alias}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    async def test_concurrent_instances(self):
        """æµ‹è¯•å¹¶å‘è®¿é—®ä¸åŒå®ä¾‹ - ä½¿ç”¨æŒä¹…å®¢æˆ·ç«¯"""
        print(f"\nğŸ§ª æµ‹è¯•å¹¶å‘è®¿é—®ä¸åŒå®ä¾‹ (æŒä¹…å®¢æˆ·ç«¯)...")
        
        async def test_instance_concurrent(alias: str):
            """å¹¶å‘æµ‹è¯•å•ä¸ªå®ä¾‹"""
            try:
                client = self.get_client(alias)
                # å‘é€æµ‹è¯•æŸ¥è¯¢
                result = await client.call("query_expert_stream",
                    question=f"å¹¶å‘æµ‹è¯• - æŒä¹…å®ä¾‹ {alias}ï¼Œè¯·å›å¤ç¡®è®¤ã€‚æ—¶é—´æˆ³: {asyncio.get_event_loop().time()}"
                )
                
                return True, alias, result
            except Exception as e:
                return False, alias, str(e)
        
        try:
            # å¹¶å‘æµ‹è¯•ä¸¤ä¸ªå®ä¾‹
            tasks = [
                test_instance_concurrent("test_no_config"),
                test_instance_concurrent("test_with_config")
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            success_count = 0
            for result in results:
                if isinstance(result, Exception):
                    print(f"   âŒ å¹¶å‘æµ‹è¯•å¼‚å¸¸: {result}")
                else:
                    success, alias, content = result
                    if success:
                        print(f"   âœ… å®ä¾‹ '{alias}' å¹¶å‘æµ‹è¯•æˆåŠŸ")
                        success_count += 1
                    else:
                        print(f"   âŒ å®ä¾‹ '{alias}' å¹¶å‘æµ‹è¯•å¤±è´¥: {content}")
            
            return success_count == len(tasks)
            
        except Exception as e:
            print(f"âŒ å¹¶å‘æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_instance_isolation(self):
        """æµ‹è¯•å®ä¾‹éš”ç¦»æ€§ - ä½¿ç”¨æŒä¹…å®¢æˆ·ç«¯"""
        print(f"\nğŸ§ª æµ‹è¯•å®ä¾‹éš”ç¦»æ€§ (æŒä¹…å®¢æˆ·ç«¯)...")
        
        try:
            # åœ¨ç¬¬ä¸€ä¸ªå®ä¾‹ä¸­è®¾ç½®é…ç½®
            client1 = self.get_client("test_no_config")
            await client1.set("test_isolation_1", "æŒä¹…å®ä¾‹1çš„é…ç½®å€¼")
            print("   âœ… æŒä¹…å®ä¾‹1è®¾ç½®é…ç½®æˆåŠŸ")
            
            # åœ¨ç¬¬äºŒä¸ªå®ä¾‹ä¸­è®¾ç½®ä¸åŒçš„é…ç½®
            client2 = self.get_client("test_with_config")
            await client2.set("test_isolation_2", "æŒä¹…å®ä¾‹2çš„é…ç½®å€¼")
            print("   âœ… æŒä¹…å®ä¾‹2è®¾ç½®é…ç½®æˆåŠŸ")
            
            # éªŒè¯æ¯ä¸ªå®ä¾‹éƒ½èƒ½è®¿é—®è‡ªå·±çš„é…ç½®
            value1 = await client1.get("test_isolation_1", "æœªè®¾ç½®")
            if value1 == "æŒä¹…å®ä¾‹1çš„é…ç½®å€¼":
                print("   âœ… æŒä¹…å®ä¾‹1èƒ½è®¿é—®è‡ªå·±çš„é…ç½®")
            else:
                print(f"   âŒ æŒä¹…å®ä¾‹1é…ç½®éªŒè¯å¤±è´¥: {value1}")
                return False
            
            value2 = await client2.get("test_isolation_2", "æœªè®¾ç½®")
            if value2 == "æŒä¹…å®ä¾‹2çš„é…ç½®å€¼":
                print("   âœ… æŒä¹…å®ä¾‹2èƒ½è®¿é—®è‡ªå·±çš„é…ç½®")
            else:
                print(f"   âŒ æŒä¹…å®ä¾‹2é…ç½®éªŒè¯å¤±è´¥: {value2}")
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ å®ä¾‹éš”ç¦»æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_configuration_differences(self):
        """æµ‹è¯•ä¸åŒé…ç½®çš„å·®å¼‚ - ä½¿ç”¨æŒä¹…å®¢æˆ·ç«¯"""
        print(f"\nğŸ§ª æµ‹è¯•é…ç½®å·®å¼‚ (æŒä¹…å®¢æˆ·ç«¯)...")
        
        try:
            configs = {}
            
            # è·å–ä¸¤ä¸ªå®ä¾‹çš„å·¥å…·ä¿¡æ¯
            for alias in ["test_no_config", "test_with_config"]:
                client = self.get_client(alias)
                tools = await client.tools()
                tool_info = await client.tool_info("query_expert_stream") if await client.has_tool("query_expert_stream") else None
                
                configs[alias] = {
                    "tool_count": len(tools),
                    "has_expert_tool": tool_info is not None,
                    "tool_description": tool_info.description if tool_info else None
                }
                
                print(f"   å®ä¾‹ '{alias}': {configs[alias]['tool_count']} ä¸ªå·¥å…·")
            
            # æ¯”è¾ƒé…ç½®
            config1 = configs["test_no_config"]
            config2 = configs["test_with_config"]
            
            print(f"   é…ç½®æ¯”è¾ƒ:")
            print(f"     test_no_config: {config1['tool_count']} å·¥å…·, query_expert_stream: {config1['has_expert_tool']}")
            print(f"     test_with_config: {config2['tool_count']} å·¥å…·, query_expert_stream: {config2['has_expert_tool']}")
            
            # éªŒè¯ä¸¤ä¸ªå®ä¾‹éƒ½æœ‰åŸºæœ¬åŠŸèƒ½
            if config1['has_expert_tool'] and config2['has_expert_tool']:
                print("   âœ… ä¸¤ä¸ªå®ä¾‹éƒ½æ”¯æŒ query_expert_stream å·¥å…·")
                return True
            else:
                print("   âŒ æŸäº›å®ä¾‹ç¼ºå°‘å¿…è¦å·¥å…·")
                return False
                
        except Exception as e:
            print(f"âŒ é…ç½®å·®å¼‚æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_config_management(self):
        """æµ‹è¯•é…ç½®ç®¡ç†åŠŸèƒ½ - ä½¿ç”¨æŒä¹…å®¢æˆ·ç«¯"""
        print(f"\nğŸ§ª æµ‹è¯•é…ç½®ç®¡ç†åŠŸèƒ½ (æŒä¹…å®¢æˆ·ç«¯)...")
        
        try:
            # ä¸ºä¸¤ä¸ªå®ä¾‹è®¾ç½®ä¸åŒçš„é…ç½®
            configs_to_test = {
                "test_no_config": {
                    "server_name": "ExpertStreamServer",
                    "log_level": "DEBUG",
                    "max_connections": 50,
                    "timeout": 60,
                    "api_key": "sk-4jkOOy4t0qnY2t0rCQbEddyZaaMpYscsGZQ32Fa34GnIND8p",
                    "model_name": "kimi-k2-0905-preview",
                    "base_url": "https://api.openai.com/v1",
                    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿæä¾›å‡†ç¡®ã€è¯¦ç»†å’Œæœ‰ç”¨çš„å›ç­”ã€‚",
                    "mcp_servers": "[]",
                    "stdio_mcp_servers": "",
                    "mongodb_url": "",
                    "history_limit": "10",
                    "enable_history": False,
                    "role": "development_assistant",
                    "tool_description": "ğŸ¤– **Development Assistant** - Professional Development Task Executor",
                    "parameter_description": "ğŸ¯ **Task Request Parameter**: Send task request to development assistant",
                    "summary_interval": 5,
                    "max_rounds": 25,
                    "summary_instruction": "You are a professional conversation analysis and requirement prediction expert.",
                    "summary_request": "Please intelligently analyze and generate a precise data retention report.",
                    "summary_length_threshold": 30000,
                    "custom_setting": "persistent_expert_server1_value"
                },
                "test_with_config": {
                    "server_name": "ExpertStreamServer", 
                    "log_level": "WARNING",
                    "max_connections": 20,
                    "timeout": 45,
                    "api_key": "sk-test-key-for-testing-purposes-only-0987654321",
                    "model_name": "gpt-4",
                    "base_url": "https://api.openai.com/v1",
                    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿé€šè¿‡å·¥å…·å¸®ç”¨æŸ¥è¯¢å½“å‰ç›®å½•ä¸‹çš„å†…å®¹ã€‚",
                    "mcp_servers": "[]",
                    "stdio_mcp_servers": "file-writer:../file_write_server/file_write_server.py--test_no_config",
                    "mongodb_url": "mongodb://localhost:27017/chat_history",
                    "history_limit": "20",
                    "enable_history": True,
                    "role": "code_reviewer",
                    "tool_description": "ğŸ”§ **Code Review Assistant** - Advanced Code Analysis Tool",
                    "parameter_description": "ğŸ“ **Code Analysis Parameter**: Submit code for professional review",
                    "summary_interval": 3,
                    "max_rounds": 15,
                    "summary_instruction": "You are an expert code analyzer. Focus on critical code patterns and potential issues.",
                    "summary_request": "Generate a comprehensive code analysis summary with actionable insights.",
                    "summary_length_threshold": 20000,
                    "custom_setting": "persistent_expert_server2_value"
                }
            }
            
            success_count = 0
            
            for alias, config_data in configs_to_test.items():
                print(f"\n   æµ‹è¯•å®ä¾‹ '{alias}' çš„é…ç½®ç®¡ç† (æŒä¹…å®¢æˆ·ç«¯)...")
                
                try:
                    client = self.get_client(alias)
                    print(f"   âœ… ä½¿ç”¨æŒä¹…å®¢æˆ·ç«¯ '{alias}'")
                    
                    # è·å–å½“å‰é…ç½®
                    current_config = await client.config()
                    print(f"   ğŸ“‹ å½“å‰é…ç½®: {len(current_config)} é¡¹")
                    
                    # æ‰¹é‡æ›´æ–°é…ç½®
                    print(f"   ğŸ”§ æ‰¹é‡æ›´æ–°é…ç½®...")
                    update_success = await client.update(**config_data)
                    if update_success:
                        print(f"   âœ… é…ç½®æ‰¹é‡æ›´æ–°æˆåŠŸ")
                    else:
                        print(f"   âš ï¸  é…ç½®æ‰¹é‡æ›´æ–°è¿”å› False")
                    
                    # é€ä¸ªè®¾ç½®å…³é”®é…ç½®é¡¹
                    key_configs = [
                        ("custom_setting", config_data["custom_setting"]),
                        ("model_name", config_data["model_name"]),
                        ("log_level", config_data["log_level"])
                    ]
                    
                    for key, value in key_configs:
                        set_success = await client.set(key, value)
                        if set_success:
                            print(f"   âœ… è®¾ç½® {key} = {value}")
                        else:
                            print(f"   âš ï¸  è®¾ç½® {key} å¤±è´¥")
                    
                    # éªŒè¯é…ç½®æ›´æ–°
                    updated_config = await client.config()
                    print(f"   ğŸ” éªŒè¯é…ç½®: {len(updated_config)} é¡¹")
                    
                    # æ£€æŸ¥å…³é”®é…ç½®é¡¹
                    expected_setting = config_data["custom_setting"]
                    actual_setting = await client.get("custom_setting", "æœªè®¾ç½®")
                    
                    if actual_setting == expected_setting:
                        print(f"   âœ… é…ç½®éªŒè¯æˆåŠŸ: custom_setting = {actual_setting}")
                        success_count += 1
                    else:
                        print(f"   âŒ é…ç½®éªŒè¯å¤±è´¥: æœŸæœ› {expected_setting}, å®é™… {actual_setting}")
                    
                    # æ˜¾ç¤ºå…¶ä»–é…ç½®é¡¹
                    model_name = await client.get("model_name", "æœªè®¾ç½®")
                    log_level = await client.get("log_level", "æœªè®¾ç½®")
                    print(f"   ğŸ“Š å…¶ä»–é…ç½®: model_name={model_name}, log_level={log_level}")
                        
                except Exception as e:
                    print(f"   âŒ å®ä¾‹ '{alias}' é…ç½®ç®¡ç†å¤±è´¥: {e}")
            
            return success_count == len(configs_to_test)
            
        except Exception as e:
            print(f"âŒ é…ç½®ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_performance_comparison(self):
        """æµ‹è¯•æ€§èƒ½å¯¹æ¯” - æŒä¹…å®¢æˆ·ç«¯ vs ä¸´æ—¶å®¢æˆ·ç«¯"""
        print(f"\nğŸ§ª æµ‹è¯•æ€§èƒ½å¯¹æ¯”...")
        
        import time
        
        # æµ‹è¯•æŒä¹…å®¢æˆ·ç«¯æ€§èƒ½
        print("   æµ‹è¯•æŒä¹…å®¢æˆ·ç«¯æ€§èƒ½...")
        start_time = time.time()
        
        for i in range(5):
            client = self.get_client("test_no_config")
            tools = await client.tools()
            
        persistent_time = time.time() - start_time
        print(f"   æŒä¹…å®¢æˆ·ç«¯ 5 æ¬¡è°ƒç”¨è€—æ—¶: {persistent_time:.3f}s")
        
        # æµ‹è¯•ä¸´æ—¶å®¢æˆ·ç«¯æ€§èƒ½
        print("   æµ‹è¯•ä¸´æ—¶å®¢æˆ·ç«¯æ€§èƒ½...")
        start_time = time.time()
        
        for i in range(5):
            async with SimpleClient(self.server_script, alias="test_no_config", config_dir=self.config_dir) as client:
                tools = await client.tools()
                
        temporary_time = time.time() - start_time
        print(f"   ä¸´æ—¶å®¢æˆ·ç«¯ 5 æ¬¡è°ƒç”¨è€—æ—¶: {temporary_time:.3f}s")
        
        # æ€§èƒ½å¯¹æ¯”
        improvement = ((temporary_time - persistent_time) / temporary_time) * 100
        print(f"   ğŸ“Š æ€§èƒ½æå‡: {improvement:.1f}% (æŒä¹…å®¢æˆ·ç«¯æ›´å¿«)")
        
        return persistent_time < temporary_time


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡
    import os
    os.environ["TESTING_MODE"] = "true"
    
    print("ğŸš€ ExpertStreamServer æŒä¹…å®¢æˆ·ç«¯æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = PersistentClientTester("./dist/expert-stream-server")
    
    try:
        # åˆå§‹åŒ–æŒä¹…å®¢æˆ·ç«¯
        await tester.setup_clients()
        
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        tests = [
            ("æ— é…ç½®å®ä¾‹æµ‹è¯•", lambda: tester.test_instance_with_alias("test_no_config")),
            ("æœ‰é…ç½®å®ä¾‹æµ‹è¯•", lambda: tester.test_instance_with_alias("test_with_config")),
            ("å¹¶å‘è®¿é—®æµ‹è¯•", tester.test_concurrent_instances),
            ("å®ä¾‹éš”ç¦»æµ‹è¯•", tester.test_instance_isolation),
            ("é…ç½®å·®å¼‚æµ‹è¯•", tester.test_configuration_differences),
            ("é…ç½®ç®¡ç†æµ‹è¯•", tester.test_config_management),
            ("æ€§èƒ½å¯¹æ¯”æµ‹è¯•", tester.test_performance_comparison),
        ]
        
        results = []
        for test_name, test_func in tests:
            print(f"\nğŸ¯ {test_name}")
            try:
                success = await test_func()
                results.append((test_name, success))
                if success:
                    print(f"âœ… {test_name} é€šè¿‡")
                else:
                    print(f"âŒ {test_name} å¤±è´¥")
            except Exception as e:
                print(f"âŒ {test_name} å¼‚å¸¸: {e}")
                results.append((test_name, False))
        
        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        
        passed = sum(1 for _, success in results if success)
        total = len(results)
        
        for test_name, success in results:
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"   {test_name}: {status}")
        
        print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼æŒä¹…å®¢æˆ·ç«¯å·¥ä½œæ­£å¸¸ã€‚")
            return 0
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’ŒæœåŠ¡å™¨çŠ¶æ€ã€‚")
            return 1
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return 1
    finally:
        # æ¸…ç†èµ„æº
        await tester.cleanup_clients()


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))