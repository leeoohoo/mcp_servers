import json
import logging
from typing import Any, Dict, AsyncGenerator
from typing_extensions import Annotated

from expert_service import ExpertService
from mcp_framework.core import EnhancedMCPServer
from mcp_framework.core.decorators import (
    Required as R,
    ServerParam, StringParam, BooleanParam, SelectParam
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("ExpertMCPServerAnnotated")


class ExpertMCPServerAnnotated(EnhancedMCPServer):
    """åŸºäºæ³¨è§£è£…é¥°å™¨çš„ä¸“å®¶MCPæœåŠ¡å™¨"""

    def __init__(self):
        super().__init__(
            name="expert-server-annotated",
            version="1.0.0",
            description="AIä¸“å®¶æœåŠ¡å™¨ï¼ŒåŸºäºæ³¨è§£è£…é¥°å™¨ç³»ç»Ÿæä¾›å®Œæ•´çš„AIå·¥å…·è°ƒç”¨ä½“ç³»"
        )
        self.expert_service = None
    
    def get_config_value(self, key: str, default=None):
        """è·å–é…ç½®å€¼çš„ç»Ÿä¸€æ–¹æ³•
        
        Args:
            key: é…ç½®é”®å
            default: é»˜è®¤å€¼
            
        Returns:
            é…ç½®å€¼æˆ–é»˜è®¤å€¼
        """
        # è°ƒç”¨çˆ¶ç±»çš„ get_config_value æ–¹æ³•ï¼Œè€Œä¸æ˜¯ç›´æ¥è®¿é—® server_config
        return super().get_config_value(key, default)
    


    @property
    def setup_tools(self):
        """è®¾ç½®å·¥å…·è£…é¥°å™¨"""
        
        # è·å–å½“å‰å·¥å…·æè¿°å’Œå‚æ•°æè¿°
        description = self.get_config_value('tool_description', 
            "ğŸ¤– **Development Assistant** - Professional Development Task Executor\n\n" +
            "## ğŸ› ï¸ Core Capabilities:\n" +
            "â€¢ **Code Development** - Implementation in various programming languages\n" +
            "â€¢ **Issue Diagnosis** - Bug fixes, performance optimization, error troubleshooting\n" +
            "â€¢ **Architecture Design** - System design, technology selection, best practices\n" +
            "â€¢ **File Operations** - Code refactoring, batch modifications, project building\n" +
            "â€¢ **Environment Setup** - Development environment configuration, deployment setup, toolchain management\n\n" +
            "## ğŸ“¤ Task Execution Results:\n" +
            "â€¢ **Task Completed** - Successfully completed development task with complete solution\n" +
            "â€¢ **Task Partially Completed** - Main functionality completed, with notes on incomplete parts and reasons\n" +
            "â€¢ **Task Failed** - Unable to complete task, detailed failure reasons and suggestions provided\n" +
            "â€¢ **Need More Information** - Task description insufficient, additional requirements needed\n" +
            "â€¢ **Task Beyond Capability** - Task complexity exceeds current processing capability\n\n" +
            "ğŸ’¡ **Working Method**: Automatically retrieves assigned development tasks, analyzes requirements, executes and provides execution status feedback."
        )
        
        parameter_description = self.get_config_value('parameter_description',
            "ğŸ¯ **Task Request Parameter**: Send task request to development assistant\n\n" +
            "ğŸ“‹ **Standard Request Format**:\n" +
            "â€¢ 'I have some development tasks, please help me complete them'\n" +
            "â€¢ 'There are several development requirements to handle, please assist'\n" +
            "â€¢ 'Please process the following development tasks'\n\n" +
            "ğŸ“ **Manager Additional Instructions**:\n" +
            "â€¢ 'Prioritize urgent tasks, focus on code quality'\n" +
            "â€¢ 'Follow company coding standards, add detailed comments'\n" +
            "â€¢ 'These tasks are complex, provide feedback if issues arise'\n" +
            "â€¢ 'Use latest tech stack, ensure code maintainability'"
        )

        @self.streaming_tool(description=description)
        async def query_expert_stream(
                question: Annotated[str, R(parameter_description)]
        ) -> AsyncGenerator[str, None]:
            """Development Assistant - Professional development task support"""
            if not question:
                yield json.dumps({"error": "Question parameter cannot be empty"}, ensure_ascii=False)
                return

            try:
                async for chunk in self.expert_service.ask_expert_stream(question):
                    # Use base class standardized method to process chunk
                    yield self._normalize_stream_chunk(chunk)
            except Exception as e:
                # Use base class error handling method
                yield await self._handle_stream_error("query_expert_stream", e)

        @self.resource(uri="config://expert", name="Expert Config", description="ä¸“å®¶æœåŠ¡å™¨é…ç½®ä¿¡æ¯")
        async def expert_config_resource(uri: str) -> Dict[str, Any]:
            """è·å–ä¸“å®¶æœåŠ¡å™¨é…ç½®ä¿¡æ¯"""
            mcp_servers_config = self.get_config_value("mcp_servers", "")
            mcp_servers = self._parse_mcp_servers_config(mcp_servers_config)
            
            stdio_mcp_servers_config = self.get_config_value("stdio_mcp_servers", "")
            stdio_mcp_servers = self._parse_mcp_servers_config(stdio_mcp_servers_config)

            return {
                "contents": [{
                    "uri": uri,
                    "mimeType": "application/json",
                    "text": json.dumps({
                        "config_info": {
                            "api_key": "***" if self.get_config_value("api_key") else "",
                            "base_url": self.get_config_value("base_url", "https://api.openai.com/v1"),
                            "model_name": self.get_config_value("model_name", "gpt-3.5-turbo"),
                            "system_prompt": self.get_config_value("system_prompt", ""),
                            "mcp_servers": mcp_servers,
                            "stdio_mcp_servers": stdio_mcp_servers
                        }
                    }, ensure_ascii=False)
                }]
            }
        
        return True

    @property
    def setup_server_params(self):
        """è®¾ç½®æœåŠ¡å™¨å‚æ•°è£…é¥°å™¨"""
        
        @self.decorators.server_param("api_key")
        async def api_key_param(
            param: Annotated[str, ServerParam(
                display_name="APIå¯†é’¥",
                description="OpenAI APIå¯†é’¥",
                param_type="password",
                required=True,
                placeholder="sk-..."
            )]
        ):
            """APIå¯†é’¥å‚æ•°"""
            pass
        
        @self.decorators.server_param("base_url")
        async def base_url_param(
            param: Annotated[str, StringParam(
                display_name="APIåŸºç¡€URL",
                description="APIåŸºç¡€URL",
                required=False,
                default_value="https://api.moonshot.cn/v1",
                placeholder="https://api.openai.com/v1"
            )]
        ):
            """APIåŸºç¡€URLå‚æ•°"""
            pass
        
        @self.decorators.server_param("model_name")
        async def model_name_param(
            param: Annotated[str, StringParam(
                display_name="æ¨¡å‹åç§°",
                description="è¾“å…¥è¦ä½¿ç”¨çš„AIæ¨¡å‹åç§°",
                default_value="kimi-k2-turbo-preview",
                required=False,
                placeholder="ä¾‹å¦‚: gpt-3.5-turbo, gpt-4, kimi-k2-turbo-preview"
            )]
        ):
            """æ¨¡å‹åç§°å‚æ•°"""
            pass
        
        @self.decorators.server_param("system_prompt")
        async def system_prompt_param(
            param: Annotated[str, StringParam(
                display_name="ç³»ç»Ÿæç¤ºè¯",
                description="ç³»ç»Ÿæç¤ºè¯",
                required=False,
                default_value="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿé€šè¿‡å·¥å…·å¸®ç”¨æŸ¥è¯¢å½“å‰ç›®å½•ä¸‹çš„å†…å®¹ã€‚",
                placeholder="è¾“å…¥ç³»ç»Ÿæç¤ºè¯..."
            )]
        ):
            """ç³»ç»Ÿæç¤ºè¯å‚æ•°"""
            pass
        
        @self.decorators.server_param("mcp_servers")
        async def mcp_servers_param(
            param: Annotated[str, StringParam(
                display_name="MCPæœåŠ¡å™¨é…ç½®",
                description="MCPæœåŠ¡å™¨é…ç½®ï¼ˆæ ¼å¼ï¼šname1:url1,name2:url2ï¼‰",
                required=False,
                default_value="file-reader: http://localhost:8001/mcp",
                placeholder="terminal-server:http://localhost:8001,file-server:http://localhost:8002"
            )]
        ):
            """MCPæœåŠ¡å™¨é…ç½®å‚æ•°"""
            pass
        
        @self.decorators.server_param("stdio_mcp_servers")
        async def stdio_mcp_servers_param(
            param: Annotated[str, StringParam(
                display_name="Stdioåè®®MCPæœåŠ¡å™¨é…ç½®",
                description="Stdioåè®®MCPæœåŠ¡å™¨é…ç½®ï¼ˆæ ¼å¼ï¼šname1:script_path1--alias,name2:script_path2--aliasï¼‰",
                required=False,
                default_value="",
                placeholder="file-manager:file_manager.py--alias,task-runner:task_runner.js--alias"
            )]
        ):
            """Stdioåè®®MCPæœåŠ¡å™¨é…ç½®å‚æ•°"""
            pass
        
        @self.decorators.server_param("mongodb_url")
        async def mongodb_url_param(
            param: Annotated[str, StringParam(
                display_name="MongoDBè¿æ¥URL",
                description="MongoDBæ•°æ®åº“è¿æ¥URLï¼Œå¦‚æœä¸é…ç½®åˆ™ä½¿ç”¨æ–‡ä»¶å­˜å‚¨",
                required=False,
                default_value="",
                placeholder="mongodb://localhost:27017/chat_history"
            )]
        ):
            """MongoDBè¿æ¥URLå‚æ•°"""
            pass
        
        @self.decorators.server_param("history_limit")
        async def history_limit_param(
            param: Annotated[str, StringParam(
                display_name="å†å²è®°å½•æŸ¥è¯¢æ¡æ•°",
                description="æ¯æ¬¡å¯¹è¯æ—¶æŸ¥è¯¢çš„å†å²è®°å½•æ¡æ•°",
                required=False,
                default_value="10",
                placeholder="10"
            )]
        ):
            """å†å²è®°å½•æŸ¥è¯¢æ¡æ•°å‚æ•°"""
            pass
        
        @self.decorators.server_param("enable_history")
        async def enable_history_param(
            param: Annotated[bool, BooleanParam(
                display_name="å¯ç”¨èŠå¤©è®°å½•",
                description="æ˜¯å¦å¯ç”¨èŠå¤©è®°å½•åŠŸèƒ½",
                required=False,
                default_value=False,
            )]
        ):
            """å¯ç”¨èŠå¤©è®°å½•å‚æ•°"""
            pass
        
        @self.decorators.server_param("role")
        async def role_param(
            param: Annotated[str, StringParam(
                display_name="è§’è‰²è®¾å®š",
                description="AIåŠ©æ‰‹çš„è§’è‰²è®¾å®š",
                required=False,
                default_value="",
                placeholder="è¾“å…¥è§’è‰²è®¾å®š..."
            )]
        ):
            """è§’è‰²è®¾å®šå‚æ•°"""
            pass
        
        @self.decorators.server_param("tool_description")
        async def tool_description_param(
            param: Annotated[str, StringParam(
                display_name="å·¥å…·æè¿°",
                description="è‡ªå®šä¹‰å·¥å…·çš„æè¿°ä¿¡æ¯",
                default_value="ğŸ¤– **Development Assistant** - Professional Development Task Executor",
                required=False
            )]
        ):
            """å·¥å…·æè¿°å‚æ•°"""
            pass
        
        @self.decorators.server_param("parameter_description")
        async def parameter_description_param(
            param: Annotated[str, StringParam(
                display_name="å‚æ•°æè¿°",
                description="è‡ªå®šä¹‰å·¥å…·å‚æ•°çš„æè¿°ä¿¡æ¯",
                default_value="ğŸ¯ **Task Request Parameter**: Send task request to development assistant",
                required=False
            )]
        ):
            """å‚æ•°æè¿°å‚æ•°"""
            pass
            
        @self.decorators.server_param("summary_interval")
        async def summary_interval_param(
            param: Annotated[int, ServerParam(
                display_name="å·¥å…·è°ƒç”¨æ€»ç»“é—´éš”",
                description="æ¯æ‰§è¡Œå¤šå°‘è½®å·¥å…·è°ƒç”¨åè¿›è¡Œä¸€æ¬¡æ€»ç»“",
                param_type="integer",
                default_value=5,
                required=False
            )]
        ):
            """å·¥å…·è°ƒç”¨æ€»ç»“é—´éš”å‚æ•°"""
            pass
            
        @self.decorators.server_param("max_rounds")
        async def max_rounds_param(
            param: Annotated[int, ServerParam(
                display_name="æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°",
                description="AIå¯¹è¯ä¸­å…è®¸çš„æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°",
                param_type="integer",
                default_value=25,
                required=False
            )]
        ):
            """æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°å‚æ•°"""
            pass
            
        @self.decorators.server_param("summary_instruction")
        async def summary_instruction_param(
            param: Annotated[str, StringParam(
                display_name="æ€»ç»“æŒ‡ä»¤å†…å®¹",
                description="AIæ€»ç»“å™¨ä½¿ç”¨çš„ç³»ç»ŸæŒ‡ä»¤å†…å®¹",
                required=False,
                default_value="You are a professional conversation analysis and requirement prediction expert. Please intelligently analyze and preserve data segments from tool call results that are crucial for subsequent operations based on the user's original requirements.",
                placeholder="è¾“å…¥æ€»ç»“æŒ‡ä»¤å†…å®¹..."
            )]
        ):
            """æ€»ç»“æŒ‡ä»¤å†…å®¹å‚æ•°"""
            pass
            
        @self.decorators.server_param("summary_request")
        async def summary_request_param(
            param: Annotated[str, StringParam(
                display_name="æ€»ç»“è¯·æ±‚å†…å®¹",
                description="AIæ€»ç»“å™¨ä½¿ç”¨çš„ç”¨æˆ·è¯·æ±‚å†…å®¹",
                required=False,
                default_value="Please intelligently analyze and generate a precise data retention report based on the user's original requirements.",
                placeholder="è¾“å…¥æ€»ç»“è¯·æ±‚å†…å®¹..."
            )]
        ):
            """æ€»ç»“è¯·æ±‚å†…å®¹å‚æ•°"""
            pass
            
        @self.decorators.server_param("summary_length_threshold")
        async def summary_length_threshold_param(
            param: Annotated[int, ServerParam(
                display_name="æ€»ç»“é•¿åº¦é˜ˆå€¼",
                description="è§¦å‘æ€»ç»“çš„æ¶ˆæ¯æ€»é•¿åº¦é˜ˆå€¼ï¼ˆå­—ç¬¦æ•°ï¼‰",
                param_type="integer",
                default_value=30000,
                required=False
            )]
        ):
            """æ€»ç»“é•¿åº¦é˜ˆå€¼å‚æ•°"""
            pass

        
        return True

    async def initialize(self) -> None:
        """åˆå§‹åŒ–æœåŠ¡å™¨"""
        import os
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼
        testing_mode = os.environ.get("TESTING_MODE", "false").lower() == "true"
        
        if testing_mode:
            logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼å·²å¯ç”¨ï¼Œè·³è¿‡ api_key éªŒè¯")

        # è§¦å‘è£…é¥°å™¨å·¥å…·æ³¨å†Œ
        _ = self.setup_tools
        # è§¦å‘æœåŠ¡å™¨å‚æ•°æ³¨å†Œ
        _ = self.setup_server_params

        # å‡†å¤‡é…ç½®å€¼å­—å…¸ï¼Œä½¿ç”¨ get_config_value æ–¹æ³•è·å–é…ç½®
        config_values = {
            "api_key": self.get_config_value("api_key", "test-api-key" if testing_mode else None),
            "base_url": self.get_config_value("base_url", "https://api.openai.com/v1"),
            "model_name": self.get_config_value("model_name", "gpt-3.5-turbo"),
            "system_prompt": self.get_config_value("system_prompt", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿæä¾›å‡†ç¡®ã€è¯¦ç»†å’Œæœ‰ç”¨çš„å›ç­”ã€‚"),
            "mcp_servers": self.get_config_value("mcp_servers", ""),
            "stdio_mcp_servers": self.get_config_value("stdio_mcp_servers", ""),
            "mongodb_url": self.get_config_value("mongodb_url", ""),
            "history_limit": self.get_config_value("history_limit", 10),
            "enable_history": self.get_config_value("enable_history", True),
            "role": self.get_config_value("role", ""),
            "tool_description": self.get_config_value("tool_description", "ğŸ¤– **Development Assistant** - Professional Development Task Executor"),
            "parameter_description": self.get_config_value("parameter_description", "ğŸ¯ **Task Request Parameter**: Send task request to development assistant"),
            "summary_interval": self.get_config_value("summary_interval", 5),
            "max_rounds": self.get_config_value("max_rounds", 25),
            "summary_instruction": self.get_config_value("summary_instruction", "You are a professional conversation analysis and requirement prediction expert. Please intelligently analyze and preserve data segments from tool call results that are crucial for subsequent operations based on the user's original requirements."),
            "summary_request": self.get_config_value("summary_request", "Please intelligently analyze and generate a precise data retention report based on the user's original requirements."),
            "summary_length_threshold": self.get_config_value("summary_length_threshold", 30000)
        }

        # ä½¿ç”¨å·¥å‚æ–¹æ³•åˆ›å»ºå¹¶åˆå§‹åŒ–ä¸“å®¶æœåŠ¡
        self.expert_service = await ExpertService.from_config(config_values)

        # ä½¿ç”¨æ¡†æ¶çš„å·¥å…·æ—¥å¿—è®°å½•åŠŸèƒ½
        self._log_tools_info()

        logger.info("âœ… Expert MCP Server (Annotated) initialized successfully")

    async def shutdown(self) -> None:
        """å…³é—­æœåŠ¡å™¨"""
        if self._initialized and self.expert_service:
            # æ­£ç¡®å…³é—­ä¸“å®¶æœåŠ¡
            try:
                await self.expert_service.shutdown()
            except Exception as e:
                logger.warning(f"å…³é—­ä¸“å®¶æœåŠ¡æ—¶å‡ºç°è­¦å‘Š: {e}")
            finally:
                self.expert_service = None
                logger.info("ğŸ›‘ Expert Serviceå·²æ¸…ç†")
        
        # è°ƒç”¨çˆ¶ç±»çš„shutdownæ–¹æ³•
        await super().shutdown()


