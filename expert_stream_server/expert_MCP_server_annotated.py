import json
import logging
from typing import Any, Dict, AsyncGenerator
from typing_extensions import Annotated

from expert_service import ExpertService
from mcp_framework.core import EnhancedMCPServer
from mcp_framework.core.decorators import (
    Required as R,
    ServerParam, StringParam, BooleanParam, SelectParam
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("ExpertMCPServerAnnotated")


class ExpertMCPServerAnnotated(EnhancedMCPServer):
    """åŸºäºæ³¨è§£è£…é¥°å™¨çš„ä¸“å®¶MCPæœåŠ¡å™¨"""

    def __init__(self):
        super().__init__(
            name="expert-server-annotated",
            version="1.0.0",
            description="AIä¸“å®¶æœåŠ¡å™¨ï¼ŒåŸºäºæ³¨è§£è£…é¥°å™¨ç³»ç»Ÿæä¾›å®Œæ•´çš„AIå·¥å…·è°ƒç”¨ä½“ç³»"
        )
        self.expert_service = None

    @property
    def setup_tools(self):
        """è®¾ç½®å·¥å…·è£…é¥°å™¨"""

        # @self.streaming_tool(
        #     description="**Development Planner** - Analyzes project status and creates development execution plans\n\n" +
        #                 "**Input Parameter**: question (string) - Development requirements or objectives\n\n" +
        #                 "**Planning Capabilities**:\n" +
        #                 "â€¢ Scan project structure and existing codebase\n" +
        #                 "â€¢ Identify tech stack and development patterns\n" +
        #                 "â€¢ Create detailed development plans\n" +
        #                 "â€¢ Plan task execution order and dependencies\n" +
        #                 "â€¢ Estimate development effort and timeline\n\n" +
        #                 "**Output**: Structured development plan containing:\n" +
        #                 "- Project analysis results\n" +
        #                 "- Priority-ordered task list\n" +
        #                 "- Specific execution instructions for each task\n" +
        #                 "- File paths and operation types\n" +
        #                 "- Inter-task dependencies\n\n" +
        #                 "**Usage**: query_expert_stream(question=\"Feature to implement or problem to solve\")"
        # )
        # async def query_expert_stream(
        #         question: Annotated[str, R(
        #             "Describe the development objective to be planned, for example:\n" +
        #             "â€¢ 'Implement user management system'\n" +
        #             "â€¢ 'Refactor existing code architecture'\n" +
        #             "â€¢ 'Add payment functionality module'\n" +
        #             "â€¢ 'Optimize system performance'\n" +
        #             "â€¢ 'Fix known bug list'"
        #         )]
        # ) -> AsyncGenerator[str, None]:
        #
        #     """Development Assistant - Professional development task support"""
        #     if not question:
        #         yield json.dumps({"error": "Question parameter cannot be empty"}, ensure_ascii=False)
        #         return
        #
        #     try:
        #         async for chunk in self.expert_service.ask_expert_stream(question):
        #             # Use base class standardized method to process chunk
        #             yield self._normalize_stream_chunk(chunk)
        #     except Exception as e:
        #         # Use base class error handling method
        #         yield await self._handle_stream_error("query_expert_stream", e)

        @self.streaming_tool(
            description="ğŸ¤– **Development Assistant** - Professional development task helper\n" +
                        "ğŸ“ **Parameter Requirements**: You MUST provide detailed requirements in the 'question' parameter\n" +
                        "ğŸ“ **File Operations**: When modifying files, you MUST include specific file paths in your question\n" +
                        "âœ… **Best Practices**: More detailed requirements = better results; simpler tasks = faster completion\n" +
                        "ğŸ”§ **Supported Features**: Code writing, file operations, project building, environment configuration, debugging & testing\n\n" +
                        "ğŸ’¡ **How to Pass Parameters**:\n" +
                        "Pass your complete request as the 'question' parameter. Include:\n" +
                        "â€¢ Task description (what you want to accomplish)\n" +
                        "â€¢ Technology stack (Python/Node.js/Java/React, etc.)\n" +
                        "â€¢ File paths (if file operations involved)\n" +
                        "â€¢ Specific requirements or constraints\n\n" +
                        "ğŸ¯ **Parameter Examples**:\n" +
                        "question='Write a Python quicksort algorithm with custom comparison function support'\n" +
                        "question='Create a React button component with loading state in ./src/components/Button.jsx'\n" +
                        "question='Add exception handling to the login function in ./api/auth.py'\n" +
                        "question='Write Jest tests for email validation in ./src/utils/validator.js'\n" +
                        "question='Optimize database queries in ./models/User.java for better performance'\n" +
                        "question='Implement a debounce hook for search functionality in React'\n" +
                        "question='Create a MySQL stored procedure to calculate monthly sales totals'\n" +
                        "question='Add CORS configuration to ./config/express.js file'"
        )
        async def query_expert_stream(
                question: Annotated[str, R(
                    "ğŸ¯ **REQUIRED PARAMETER**: Pass your complete development request here.\n\n" +
                    "ğŸ“‹ **What to include in this parameter**:\n" +
                    "â€¢ Detailed task description\n" +
                    "â€¢ Technology stack specification\n" +
                    "â€¢ Complete file paths (for file operations)\n" +
                    "â€¢ Specific requirements or constraints\n\n" +
                    "âš ï¸ **CRITICAL**: File operations require full file paths!\n\n" +
                    "âœ… **Good parameter examples**:\n" +
                    "â€¢ 'Write a Python decorator to measure execution time and log results'\n" +
                    "â€¢ 'Add user authentication middleware to ./src/middleware/auth.js'\n" +
                    "â€¢ 'Create a responsive navbar component using Tailwind CSS'\n" +
                    "â€¢ 'Fix memory leak in ./src/services/DataProcessor.java'\n" +
                    "â€¢ 'Implement Redis caching for user sessions in Node.js Express app'\n\n" +
                    "âŒ **Avoid vague requests like**:\n" +
                    "â€¢ 'Help me with code'\n" +
                    "â€¢ 'Fix this file' (without file path)\n" +
                    "â€¢ 'Make it better' (without specifics)"
                )]
        ) -> AsyncGenerator[str, None]:
            """Development Assistant - Professional development task support"""
            if not question:
                yield json.dumps({"error": "Question parameter cannot be empty"}, ensure_ascii=False)
                return

            try:
                async for chunk in self.expert_service.ask_expert_stream(question):
                    # Use base class standardized method to process chunk
                    yield self._normalize_stream_chunk(chunk)
            except Exception as e:
                # Use base class error handling method
                yield await self._handle_stream_error("query_expert_stream", e)

        @self.resource(uri="config://expert", name="Expert Config", description="ä¸“å®¶æœåŠ¡å™¨é…ç½®ä¿¡æ¯")
        async def expert_config_resource(uri: str) -> Dict[str, Any]:
            """è·å–ä¸“å®¶æœåŠ¡å™¨é…ç½®ä¿¡æ¯"""
            config = self.server_config
            mcp_servers_config = config.get("mcp_servers", "")
            mcp_servers = self._parse_mcp_servers_config(mcp_servers_config)

            return {
                "contents": [{
                    "uri": uri,
                    "mimeType": "application/json",
                    "text": json.dumps({
                        "config_info": {
                            "api_key": "***" if config.get("api_key") else "",
                            "base_url": config.get("base_url", "https://api.openai.com/v1"),
                            "model_name": config.get("model_name", "gpt-3.5-turbo"),
                            "system_prompt": config.get("system_prompt", ""),
                            "mcp_servers": mcp_servers
                        }
                    }, ensure_ascii=False)
                }]
            }
        
        return True

    @property
    def setup_server_params(self):
        """è®¾ç½®æœåŠ¡å™¨å‚æ•°è£…é¥°å™¨"""
        
        @self.decorators.server_param("api_key")
        async def api_key_param(
            param: Annotated[str, ServerParam(
                display_name="APIå¯†é’¥",
                description="OpenAI APIå¯†é’¥",
                param_type="password",
                required=True,
                placeholder="sk-..."
            )]
        ):
            """APIå¯†é’¥å‚æ•°"""
            pass
        
        @self.decorators.server_param("base_url")
        async def base_url_param(
            param: Annotated[str, StringParam(
                display_name="APIåŸºç¡€URL",
                description="APIåŸºç¡€URL",
                required=False,
                default_value="https://api.moonshot.cn/v1",
                placeholder="https://api.openai.com/v1"
            )]
        ):
            """APIåŸºç¡€URLå‚æ•°"""
            pass
        
        @self.decorators.server_param("model_name")
        async def model_name_param(
            param: Annotated[str, SelectParam(
                display_name="æ¨¡å‹åç§°",
                description="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹",
                options=["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o", "kimi-k2-turbo-preview"],
                default_value="kimi-k2-turbo-preview",
                required=False
            )]
        ):
            """æ¨¡å‹åç§°å‚æ•°"""
            pass
        
        @self.decorators.server_param("system_prompt")
        async def system_prompt_param(
            param: Annotated[str, StringParam(
                display_name="ç³»ç»Ÿæç¤ºè¯",
                description="ç³»ç»Ÿæç¤ºè¯",
                required=False,
                default_value="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿé€šè¿‡å·¥å…·å¸®ç”¨æŸ¥è¯¢å½“å‰ç›®å½•ä¸‹çš„å†…å®¹ã€‚",
                placeholder="è¾“å…¥ç³»ç»Ÿæç¤ºè¯..."
            )]
        ):
            """ç³»ç»Ÿæç¤ºè¯å‚æ•°"""
            pass
        
        @self.decorators.server_param("mcp_servers")
        async def mcp_servers_param(
            param: Annotated[str, StringParam(
                display_name="MCPæœåŠ¡å™¨é…ç½®",
                description="MCPæœåŠ¡å™¨é…ç½®ï¼ˆæ ¼å¼ï¼šname1:url1,name2:url2ï¼‰",
                required=False,
                default_value="file-reader: http://localhost:8001/mcp",
                placeholder="terminal-server:http://localhost:8001,file-server:http://localhost:8002"
            )]
        ):
            """MCPæœåŠ¡å™¨é…ç½®å‚æ•°"""
            pass
        
        @self.decorators.server_param("mongodb_url")
        async def mongodb_url_param(
            param: Annotated[str, StringParam(
                display_name="MongoDBè¿æ¥URL",
                description="MongoDBæ•°æ®åº“è¿æ¥URLï¼Œå¦‚æœä¸é…ç½®åˆ™ä½¿ç”¨æ–‡ä»¶å­˜å‚¨",
                required=False,
                default_value="",
                placeholder="mongodb://localhost:27017/chat_history"
            )]
        ):
            """MongoDBè¿æ¥URLå‚æ•°"""
            pass
        
        @self.decorators.server_param("history_limit")
        async def history_limit_param(
            param: Annotated[str, StringParam(
                display_name="å†å²è®°å½•æŸ¥è¯¢æ¡æ•°",
                description="æ¯æ¬¡å¯¹è¯æ—¶æŸ¥è¯¢çš„å†å²è®°å½•æ¡æ•°",
                required=False,
                default_value="10",
                placeholder="10"
            )]
        ):
            """å†å²è®°å½•æŸ¥è¯¢æ¡æ•°å‚æ•°"""
            pass
        
        @self.decorators.server_param("enable_history")
        async def enable_history_param(
            param: Annotated[bool, BooleanParam(
                display_name="å¯ç”¨èŠå¤©è®°å½•",
                description="æ˜¯å¦å¯ç”¨èŠå¤©è®°å½•åŠŸèƒ½",
                required=False,
                default_value=False,
            )]
        ):
            """å¯ç”¨èŠå¤©è®°å½•å‚æ•°"""
            pass
        
        @self.decorators.server_param("role")
        async def role_param(
            param: Annotated[str, StringParam(
                display_name="è§’è‰²è®¾å®š",
                description="AIåŠ©æ‰‹çš„è§’è‰²è®¾å®š",
                required=False,
                default_value="",
                placeholder="è¾“å…¥è§’è‰²è®¾å®š..."
            )]
        ):
            """è§’è‰²è®¾å®šå‚æ•°"""
            pass
        
        return True

    async def initialize(self) -> None:
        """åˆå§‹åŒ–æœåŠ¡å™¨"""
        # ä½¿ç”¨æ¡†æ¶çš„é€šç”¨é…ç½®å¤„ç†æµç¨‹
        config_values = self._setup_decorators_and_log_config(
            required_keys=["api_key"],
            config_defaults={
                "api_key": None,
                "base_url": "https://api.openai.com/v1",
                "model_name": "gpt-3.5-turbo",
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿæä¾›å‡†ç¡®ã€è¯¦ç»†å’Œæœ‰ç”¨çš„å›ç­”ã€‚",
                "mcp_servers": ""
            }
        )

        # ä½¿ç”¨å·¥å‚æ–¹æ³•åˆ›å»ºå¹¶åˆå§‹åŒ–ä¸“å®¶æœåŠ¡
        self.expert_service = await ExpertService.from_config(config_values)

        # ä½¿ç”¨æ¡†æ¶çš„å·¥å…·æ—¥å¿—è®°å½•åŠŸèƒ½
        self._log_tools_info()

        logger.info("âœ… Expert MCP Server (Annotated) initialized successfully")

    async def shutdown(self) -> None:
        """å…³é—­æœåŠ¡å™¨"""
        if self._initialized and self.expert_service:
            # æ­£ç¡®å…³é—­ä¸“å®¶æœåŠ¡
            try:
                await self.expert_service.shutdown()
            except Exception as e:
                logger.warning(f"å…³é—­ä¸“å®¶æœåŠ¡æ—¶å‡ºç°è­¦å‘Š: {e}")
            finally:
                self.expert_service = None
                logger.info("ğŸ›‘ Expert Serviceå·²æ¸…ç†")
        
        # è°ƒç”¨çˆ¶ç±»çš„shutdownæ–¹æ³•
        await super().shutdown()


