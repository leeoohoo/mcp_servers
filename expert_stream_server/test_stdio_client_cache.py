#!/usr/bin/env python3
"""
æµ‹è¯• stdio å®¢æˆ·ç«¯ç¼“å­˜ä¼˜åŒ–æ•ˆæœ
"""

import asyncio
import time
import logging
from mcp_tool_execute import McpToolExecute

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("StdioClientCacheTest")


async def test_stdio_client_cache_performance():
    """æµ‹è¯• stdio å®¢æˆ·ç«¯ç¼“å­˜çš„æ€§èƒ½æå‡"""
    
    # é…ç½®æµ‹è¯•ç”¨çš„ stdio MCP æœåŠ¡å™¨
    stdio_mcp_servers = [
        {
            "name": "Expert Stream Server",
            "command": "python /Users/lilei/project/learn/mcp_servers/expert_stream_server/expert_stream_server.py",
            "alias": "test_cache_performance",
            "protocol": "stdio"
        }
    ]
    
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯• stdio å®¢æˆ·ç«¯ç¼“å­˜æ€§èƒ½...")
    
    # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ­£ç¡®æ¸…ç†
    async with McpToolExecute([], stdio_mcp_servers) as executor:
        
        # æµ‹è¯•å‚æ•°
        test_calls = 5
        tool_name = "query_expert_stream"
        test_arguments = {"question": "ä»€ä¹ˆæ˜¯Pythonï¼Ÿ"}
        
        # è·å–ç¬¬ä¸€ä¸ª stdio æœåŠ¡å™¨çš„ä¿¡æ¯
        server_info = stdio_mcp_servers[0]
        server_name = server_info["name"]
        command = server_info["command"]
        alias = server_info["alias"]
        
        logger.info(f"ğŸ“Š å‡†å¤‡è¿›è¡Œ {test_calls} æ¬¡è¿ç»­è°ƒç”¨æµ‹è¯•...")
        logger.info(f"   æœåŠ¡å™¨: {server_name}")
        logger.info(f"   å·¥å…·: {tool_name}")
        logger.info(f"   åˆ«å: {alias}")
        
        # è®°å½•æ¯æ¬¡è°ƒç”¨çš„æ—¶é—´
        call_times = []
        total_start_time = time.time()
        
        for i in range(test_calls):
            logger.info(f"ğŸ”§ æ‰§è¡Œç¬¬ {i+1}/{test_calls} æ¬¡è°ƒç”¨...")
            
            call_start_time = time.time()
            
            try:
                # è°ƒç”¨ stdio å·¥å…·
                result_chunks = []
                async for chunk in executor.call_stdio_tool_stream(
                    server_name, command, alias, tool_name, test_arguments
                ):
                    result_chunks.append(chunk)
                
                call_end_time = time.time()
                call_duration = call_end_time - call_start_time
                call_times.append(call_duration)
                
                total_content_length = sum(len(str(chunk)) for chunk in result_chunks)
                
                logger.info(f"   âœ… ç¬¬ {i+1} æ¬¡è°ƒç”¨å®Œæˆ")
                logger.info(f"      è€—æ—¶: {call_duration:.3f}s")
                logger.info(f"      å“åº”é•¿åº¦: {total_content_length} å­—ç¬¦")
                logger.info(f"      å“åº”å—æ•°: {len(result_chunks)}")
                
                if i == 0:
                    logger.info(f"      é¦–æ¬¡è°ƒç”¨ï¼ˆåŒ…å«å®¢æˆ·ç«¯åˆ›å»ºï¼‰")
                else:
                    logger.info(f"      ç¼“å­˜è°ƒç”¨ï¼ˆå¤ç”¨å®¢æˆ·ç«¯ï¼‰")
                
            except Exception as e:
                logger.error(f"   âŒ ç¬¬ {i+1} æ¬¡è°ƒç”¨å¤±è´¥: {e}")
                call_times.append(float('inf'))
        
        total_end_time = time.time()
        total_duration = total_end_time - total_start_time
        
        # åˆ†ææ€§èƒ½æ•°æ®
        logger.info(f"\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœåˆ†æ:")
        logger.info(f"=" * 60)
        
        if len(call_times) > 0 and all(t != float('inf') for t in call_times):
            first_call_time = call_times[0]
            cached_call_times = call_times[1:] if len(call_times) > 1 else []
            
            logger.info(f"   é¦–æ¬¡è°ƒç”¨è€—æ—¶: {first_call_time:.3f}s ï¼ˆåŒ…å«å®¢æˆ·ç«¯åˆ›å»ºï¼‰")
            
            if cached_call_times:
                avg_cached_time = sum(cached_call_times) / len(cached_call_times)
                min_cached_time = min(cached_call_times)
                max_cached_time = max(cached_call_times)
                
                logger.info(f"   ç¼“å­˜è°ƒç”¨å¹³å‡è€—æ—¶: {avg_cached_time:.3f}s")
                logger.info(f"   ç¼“å­˜è°ƒç”¨æœ€å¿«: {min_cached_time:.3f}s")
                logger.info(f"   ç¼“å­˜è°ƒç”¨æœ€æ…¢: {max_cached_time:.3f}s")
                
                # è®¡ç®—æ€§èƒ½æå‡
                if avg_cached_time > 0:
                    speedup = (first_call_time - avg_cached_time) / first_call_time * 100
                    logger.info(f"   æ€§èƒ½æå‡: {speedup:.1f}% ï¼ˆç¼“å­˜è°ƒç”¨æ¯”é¦–æ¬¡è°ƒç”¨å¿«ï¼‰")
                    
                    if speedup > 0:
                        logger.info(f"   âœ… å®¢æˆ·ç«¯ç¼“å­˜ä¼˜åŒ–ç”Ÿæ•ˆï¼")
                    else:
                        logger.info(f"   âš ï¸ ç¼“å­˜æ•ˆæœä¸æ˜æ˜¾ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            
            logger.info(f"   æ€»è€—æ—¶: {total_duration:.3f}s")
            logger.info(f"   å¹³å‡æ¯æ¬¡è°ƒç”¨: {sum(call_times)/len(call_times):.3f}s")
            
        else:
            logger.error(f"   âŒ æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•åˆ†ææ€§èƒ½æ•°æ®")
        
        # æ£€æŸ¥ç¼“å­˜çŠ¶æ€
        cache_count = len(executor._stdio_clients)
        logger.info(f"\nğŸ” ç¼“å­˜çŠ¶æ€æ£€æŸ¥:")
        logger.info(f"   å½“å‰ç¼“å­˜çš„å®¢æˆ·ç«¯æ•°é‡: {cache_count}")
        
        if cache_count > 0:
            for cache_key in executor._stdio_clients.keys():
                logger.info(f"   ç¼“å­˜é”®: {cache_key}")
        
        logger.info(f"\nâœ… æµ‹è¯•å®Œæˆï¼Œå®¢æˆ·ç«¯å°†è‡ªåŠ¨æ¸…ç†...")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await test_stdio_client_cache_performance()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())