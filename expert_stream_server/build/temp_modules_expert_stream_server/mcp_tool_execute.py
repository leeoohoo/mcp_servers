import json
import logging
import uuid
from typing import Any, Dict, List, Optional, AsyncGenerator
import aiohttp

# é…ç½®æ—¥å¿—
logger = logging.getLogger("McpToolExecute")


class McpToolExecute:
    """MCPå·¥å…·æ‰§è¡Œå™¨"""

    def __init__(self, mcp_servers: List[Dict[str, str]]):
        self.mcp_servers = mcp_servers
        self.tools = []
        self.tool_metadata = {}  # å­˜å‚¨å·¥å…·å…ƒæ•°æ®

    async def init(self):
        """åˆå§‹åŒ–ï¼Œæ„å»ºå·¥å…·åˆ—è¡¨"""
        await self.build_tools()

    # execute éæµå¼æ–¹æ³•å·²ç§»é™¤

    async def execute_stream(self, tool_calls: List[Dict[str, Any]], callback=None) -> AsyncGenerator[Dict[str, Any], None]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰"""
        logger.info(f"ğŸ”§ å¼€å§‹æ‰§è¡Œæµå¼å·¥å…·è°ƒç”¨ï¼Œå…± {len(tool_calls)} ä¸ªå·¥å…·")

        for i, tool_call in enumerate(tool_calls):
            stream_generator = None
            try:
                # ç¡®ä¿tool_callæ˜¯å­—å…¸ç±»å‹
                if not isinstance(tool_call, dict):
                    logger.error(f"âŒ å·¥å…·è°ƒç”¨ä¸æ˜¯å­—å…¸ç±»å‹: {type(tool_call)} - {tool_call}")
                    continue

                # è§£æå·¥å…·è°ƒç”¨
                tool_name = tool_call.get('function', {}).get('name') or tool_call.get('name')
                tool_args = tool_call.get('function', {}).get('arguments') or tool_call.get('arguments', {})

                logger.info(f"ğŸ”§ æ‰§è¡Œæµå¼å·¥å…· {i + 1}/{len(tool_calls)}: {tool_name}")

                # ç¡®ä¿tool_argsæ˜¯æ­£ç¡®çš„ç±»å‹
                if isinstance(tool_args, str):
                    try:
                        tool_args = json.loads(tool_args)
                    except json.JSONDecodeError:
                        logger.warning(f"âŒ Failed to parse tool arguments: {tool_args}")
                        tool_args = {}
                elif not isinstance(tool_args, dict):
                    logger.warning(f"âŒ å·¥å…·å‚æ•°ä¸æ˜¯å­—å…¸ç±»å‹: {type(tool_args)} - {tool_args}ï¼Œè½¬æ¢ä¸ºç©ºå­—å…¸")
                    tool_args = {}

                # æŸ¥æ‰¾å·¥å…·ä¿¡æ¯
                tool_info = self.find_tool_info(tool_name)
                if not tool_info:
                    raise Exception(f"Tool not found: {tool_name}")

                # é¦–å…ˆå°è¯•æµå¼è°ƒç”¨
                accumulated_content = ""
                stream_success = False
                tool_call_id = tool_call.get('id', f"call_{uuid.uuid4().hex[:16]}")

                try:
                    stream_generator = self.call_mcp_tool_stream(
                        tool_info['server_url'],
                        tool_info['original_name'],
                        tool_args
                    )

                    logger.info(f"ğŸ”§ å¼€å§‹æµå¼è°ƒç”¨å·¥å…·: {tool_name}")
                    chunk_count = 0
                    
                    async for chunk in stream_generator:
                        # å®‰å…¨åœ°å¤„ç†ä¸åŒç±»å‹çš„ chunk
                        chunk_str = self._safe_chunk_to_string(chunk)
                        accumulated_content += chunk_str
                        chunk_count += 1

                        logger.debug(f"ğŸ”§ å·¥å…· {tool_name} æ”¶åˆ°ç¬¬ {chunk_count} ä¸ªæµå¼å—: {chunk_str[:100]}...")

                        if callback:
                            callback('tool_stream_chunk', {
                                'tool_name': tool_name,
                                'chunk': chunk_str
                            })

                        # ç”Ÿæˆæµå¼ç»“æœ
                        yield {
                            'tool_call_id': tool_call_id,
                            'role': 'tool',
                            'name': tool_name,
                            'content': chunk_str,
                            'is_stream': True
                        }

                    stream_success = True
                    logger.info(f"âœ… å·¥å…· {tool_name} æµå¼è°ƒç”¨æˆåŠŸï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ªå—ï¼Œç´¯ç§¯å†…å®¹é•¿åº¦: {len(accumulated_content)}")

                except GeneratorExit:
                    logger.info(f"ğŸ›‘ å·¥å…· {tool_name} çš„æµå¼æ‰§è¡Œè¢«æå‰ç»ˆæ­¢")
                    # å³ä½¿è¢«æå‰ç»ˆæ­¢ï¼Œä¹Ÿè¦ç”Ÿæˆæœ€ç»ˆç»“æœ
                    if accumulated_content:
                        logger.info(f"ğŸ”§ å·¥å…· {tool_name} è¢«ç»ˆæ­¢ä½†æœ‰ç´¯ç§¯å†…å®¹ï¼Œç”Ÿæˆæœ€ç»ˆç»“æœ")
                        yield {
                            'tool_call_id': tool_call_id,
                            'role': 'tool',
                            'name': tool_name,
                            'content': accumulated_content,
                            'is_stream': False,
                            'is_final': True
                        }
                    return  # ç›´æ¥è¿”å›ï¼Œä¸è¦é‡æ–°æŠ›å‡º

                except Exception as stream_error:
                    logger.error(f"âŒ æµå¼è°ƒç”¨å¤±è´¥: {stream_error}")
                    raise stream_error

                # åªæœ‰æµå¼è°ƒç”¨æˆåŠŸæ—¶æ‰ç”Ÿæˆæœ€ç»ˆç»“æœ
                if stream_success:
                    logger.info(f"ğŸ”§ å·¥å…· {tool_name} å‡†å¤‡ç”Ÿæˆæœ€ç»ˆç»“æœï¼Œç´¯ç§¯å†…å®¹é•¿åº¦: {len(accumulated_content)}")
                    logger.info(f"ğŸ”§ ç´¯ç§¯å†…å®¹é¢„è§ˆ: {accumulated_content[:200]}...")
                    
                    yield {
                        'tool_call_id': tool_call_id,
                        'role': 'tool',
                        'name': tool_name,
                        'content': accumulated_content,
                        'is_stream': False,
                        'is_final': True
                    }
                    logger.info(f"âœ… æµå¼å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸï¼Œæœ€ç»ˆç»“æœå·²ç”Ÿæˆ")

            except GeneratorExit:
                logger.info(f"ğŸ›‘ å·¥å…·è°ƒç”¨æµè¢«æå‰ç»ˆæ­¢")
                # å³ä½¿è¢«æå‰ç»ˆæ­¢ï¼Œä¹Ÿè¦ç¡®ä¿å·²å¤„ç†çš„å·¥å…·æœ‰æœ€ç»ˆç»“æœ
                if 'accumulated_content' in locals() and accumulated_content:
                    logger.info(f"ğŸ”§ å·¥å…· {tool_name} æµè¢«ç»ˆæ­¢ä½†æœ‰ç´¯ç§¯å†…å®¹ï¼Œç”Ÿæˆæœ€ç»ˆç»“æœ")
                    yield {
                        'tool_call_id': tool_call.get('id', f"call_{uuid.uuid4().hex[:16]}"),
                        'role': 'tool',
                        'name': tool_name,
                        'content': accumulated_content,
                        'is_stream': False,
                        'is_final': True
                    }
                return  # ç›´æ¥è¿”å›ï¼Œä¸è¦é‡æ–°æŠ›å‡º

            except Exception as e:
                logger.error(f"âŒ Failed to execute tool {tool_name}: {e}")
                yield {
                    'tool_call_id': tool_call.get('id', f"call_{uuid.uuid4().hex[:16]}"),
                    'role': 'tool',
                    'name': tool_name,
                    'content': json.dumps({'error': str(e)}, ensure_ascii=False),
                    'is_stream': False,
                    'is_final': True,
                    'is_error': True
                }
            finally:
                # ç¡®ä¿æµå¼ç”Ÿæˆå™¨è¢«æ­£ç¡®å…³é—­
                if stream_generator:
                    try:
                        await stream_generator.aclose()
                    except Exception as close_error:
                        logger.debug(f"ğŸ§¹ å…³é—­æµå¼ç”Ÿæˆå™¨: {close_error}")

        logger.info(f"ğŸ”§ æµå¼å·¥å…·è°ƒç”¨å®Œæˆ")

    def _safe_chunk_to_string(self, chunk) -> str:
        """å®‰å…¨åœ°å°†chunkè½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
        if isinstance(chunk, str):
            return chunk
        elif isinstance(chunk, (list, tuple)):
            try:
                if all(isinstance(item, str) for item in chunk):
                    return ''.join(chunk)
                else:
                    return json.dumps(chunk, ensure_ascii=False)
            except Exception:
                return str(chunk)
        elif isinstance(chunk, dict):
            try:
                return json.dumps(chunk, ensure_ascii=False)
            except Exception:
                return str(chunk)
        elif chunk is None:
            return ""
        else:
            return str(chunk)


    def find_tool_info(self, tool_name: str) -> Optional[Dict[str, str]]:
        """æ ¹æ®å·¥å…·åç§°æŸ¥æ‰¾å·¥å…·ä¿¡æ¯"""
        return self.tool_metadata.get(tool_name)

    async def call_mcp_tool_stream(self, server_url: str, tool_name: str, arguments: Dict[str, Any]) -> AsyncGenerator[str, None]:
        """è°ƒç”¨MCPå·¥å…·ï¼ˆæµå¼ç‰ˆæœ¬ï¼Œä½¿ç”¨è¿œç«¯ SSE /sse/tool/call æ¥å£ï¼‰"""
        session = None
        response = None

        # è®¡ç®— SSE æ¥å£åœ°å€
        sse_url = server_url
        if sse_url.endswith('/mcp'):
            sse_url = sse_url[:-4] + '/sse/tool/call'
        elif '/mcp' in sse_url:
            sse_url = sse_url.replace('/mcp', '/sse/tool/call')
        else:
            sse_url = sse_url.rstrip('/') + '/sse/tool/call'

        logger.info(f"ğŸ”§ è°ƒç”¨SSEæ¥å£: {sse_url}")

        try:
            headers = {
                'Accept': 'text/event-stream',
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive'
            }

            payload = {
                'tool_name': tool_name,
                'arguments': arguments or {}
            }

            logger.info(f"ğŸ”§ å‘é€è¯·æ±‚: {payload}")

            timeout = aiohttp.ClientTimeout(total=120, connect=10)
            session = aiohttp.ClientSession(timeout=timeout)
            response = await session.post(sse_url, json=payload, headers=headers)

            logger.info(f"ğŸ”§ å“åº”çŠ¶æ€: {response.status}")

            if response.status != 200:
                error_text = await response.text()
                logger.error(f"âŒ HTTPé”™è¯¯: {response.status} - {error_text}")
                raise Exception(f"HTTP {response.status}: {error_text}")

            content_type = response.headers.get('content-type', '')
            if 'text/event-stream' not in content_type:
                error_text = await response.text()
                logger.error(f"âŒ éSSEå“åº”: {content_type} - {error_text}")
                raise Exception(f"Expected SSE response but got {content_type}: {error_text}")

            # è§£æ SSE æµ
            buffer = ""
            chunk_count = 0

            logger.info(f"ğŸ”§ å¼€å§‹è¯»å–SSEæµ...")

            async for chunk_bytes in response.content.iter_chunked(1024):
                chunk_count += 1
                chunk_str = chunk_bytes.decode('utf-8')
                buffer += chunk_str

                # å¤„ç†å®Œæ•´çš„äº‹ä»¶ï¼ˆä»¥\n\nåˆ†éš”ï¼‰
                while '\n\n' in buffer:
                    event_block, buffer = buffer.split('\n\n', 1)

                    if not event_block.strip():
                        continue

                    # è§£æäº‹ä»¶å—
                    event_type = None
                    data_content = ""

                    for line in event_block.split('\n'):
                        line = line.strip()
                        if line.startswith('event:'):
                            event_type = line[6:].strip()
                        elif line.startswith('data:'):
                            data_content = line[5:].strip()

                    # å¤„ç†ä¸åŒç±»å‹çš„äº‹ä»¶
                    if event_type == 'error':
                        logger.error(f"âŒ æ”¶åˆ°é”™è¯¯äº‹ä»¶: {data_content}")
                        try:
                            error_data = json.loads(data_content) if data_content else {}
                            error_msg = error_data.get('message', data_content)
                        except:
                            error_msg = data_content
                        raise Exception(f"Remote SSE error: {error_msg}")

                    elif event_type == 'end':
                        logger.info(f"ğŸ”§ æ”¶åˆ°ç»“æŸäº‹ä»¶")
                        return

                    elif event_type == 'data' or not event_type:
                        # å¤„ç†æ•°æ®äº‹ä»¶
                        if data_content:
                            try:
                                data_obj = json.loads(data_content)

                                # æ ¹æ®æ•°æ®ç±»å‹æå–å†…å®¹
                                content_to_yield = None

                                if isinstance(data_obj, dict):
                                    # ä¼˜å…ˆæŸ¥æ‰¾ chunk å­—æ®µ
                                    if 'chunk' in data_obj:
                                        content_to_yield = str(data_obj['chunk'])
                                    # æŸ¥æ‰¾ display å­—æ®µï¼ˆé¡¹ç›®ç»“æ„ç­‰ï¼‰
                                    elif 'display' in data_obj:
                                        content_to_yield = str(data_obj['display']) + '\n'
                                    # æŸ¥æ‰¾ content å­—æ®µ
                                    elif 'content' in data_obj:
                                        content_to_yield = str(data_obj['content'])
                                    # æŸ¥æ‰¾åµŒå¥—çš„æ•°æ®
                                    elif 'data' in data_obj and isinstance(data_obj['data'], dict):
                                        nested_data = data_obj['data']
                                        if 'chunk' in nested_data:
                                            content_to_yield = str(nested_data['chunk'])
                                        elif 'display' in nested_data:
                                            content_to_yield = str(nested_data['display']) + '\n'
                                        elif 'content' in nested_data:
                                            content_to_yield = str(nested_data['content'])

                                    # å¿½ç•¥æŸäº›æ§åˆ¶æ¶ˆæ¯
                                    data_type = data_obj.get('type', '')
                                    if data_type in ['structure_start', 'structure_complete']:
                                        continue

                                if content_to_yield:
                                    logger.info(f"ğŸ”§ æå–åˆ°å†…å®¹ï¼Œé•¿åº¦: {len(content_to_yield)}")
                                    yield content_to_yield
                                else:
                                    logger.debug(f"ğŸ”§ æ•°æ®å¯¹è±¡ä¸­æ²¡æœ‰æ‰¾åˆ°å¯ç”¨å†…å®¹: {data_obj}")

                            except json.JSONDecodeError as e:
                                logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹: {repr(data_content)}")
                                # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›å†…å®¹
                                if data_content:
                                    logger.info(f"ğŸ”§ ç›´æ¥è¿”å›éJSONå†…å®¹ï¼Œé•¿åº¦: {len(data_content)}")
                                    yield data_content
                    else:
                        logger.debug(f"ğŸ”§ å¿½ç•¥æœªçŸ¥äº‹ä»¶ç±»å‹: {event_type}")

            # å¤„ç†ç¼“å†²åŒºä¸­å‰©ä½™çš„ä¸å®Œæ•´äº‹ä»¶
            if buffer.strip():
                logger.warning(f"âš ï¸ ç¼“å†²åŒºä¸­æœ‰æœªå¤„ç†çš„å†…å®¹: {repr(buffer)}")

            logger.info(f"ğŸ”§ SSEæµè¯»å–å®Œæˆï¼Œå…±å¤„ç† {chunk_count} ä¸ªchunk")

        except GeneratorExit:
            logger.info(f"ğŸ›‘ MCPå·¥å…·æµå¼è°ƒç”¨è¢«æå‰ç»ˆæ­¢: {tool_name}")
            return
        except Exception as e:
            logger.error(f"âŒ MCPå·¥å…·æµå¼è°ƒç”¨å¤±è´¥ {tool_name}: {e}")
            raise
        finally:
            await self._cleanup_stream_resources(response, session, tool_name)

    async def _cleanup_stream_resources(self, response, session, tool_name: str):
        """æ¸…ç†æµå¼èµ„æº"""
        try:
            if response:
                try:
                    # ç¡®ä¿å“åº”å†…å®¹è¢«å®Œå…¨æ¶ˆè´¹æˆ–å…³é—­
                    if not response.closed:
                        logger.debug(f"ğŸ§¹ æ­£åœ¨å…³é—­å“åº”æµ: {tool_name}")
                        response.close()
                except Exception as close_error:
                    logger.warning(f"âš ï¸ å…³é—­å“åº”æ—¶å‡ºç°è­¦å‘Š {tool_name}: {close_error}")

            if session:
                try:
                    if not session.closed:
                        logger.debug(f"ğŸ§¹ æ­£åœ¨å…³é—­ä¼šè¯: {tool_name}")
                        await session.close()
                except Exception as close_error:
                    logger.warning(f"âš ï¸ å…³é—­ä¼šè¯æ—¶å‡ºç°è­¦å‘Š {tool_name}: {close_error}")

        except Exception as cleanup_error:
            logger.warning(f"âš ï¸ æ¸…ç†èµ„æºæ—¶å‡ºç°è­¦å‘Š {tool_name}: {cleanup_error}")

    def _extract_content_as_string(self, result) -> str:
        """ä»ç»“æœä¸­æå–å†…å®¹å¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
        if isinstance(result, dict):
            content = result.get('content', '')
            if isinstance(content, str):
                return content
            elif isinstance(content, (list, dict)):
                return json.dumps(content, ensure_ascii=False)
            elif content is not None:
                return str(content)
            else:
                # å¦‚æœæ²¡æœ‰contentå­—æ®µï¼Œè¿”å›æ•´ä¸ªresult
                return json.dumps(result, ensure_ascii=False) if result else ""
        elif isinstance(result, str):
            return result
        elif isinstance(result, (list, dict)):
            return json.dumps(result, ensure_ascii=False)
        elif result is not None:
            return str(result)
        else:
            return ""


    async def build_tools(self):
        """æ„å»ºå·¥å…·åˆ—è¡¨"""
        try:
            self.tools = []
            self.tool_metadata = {}

            logger.info(f"ğŸ”§ å¼€å§‹æ„å»ºå·¥å…·åˆ—è¡¨ï¼Œé…ç½®çš„MCPæœåŠ¡å™¨æ•°é‡: {len(self.mcp_servers)}")

            for mcp_server in self.mcp_servers:
                try:
                    logger.info(f"ğŸ”§ æ­£åœ¨ä»MCPæœåŠ¡å™¨è·å–å·¥å…·: {mcp_server['name']} ({mcp_server['url']})")

                    # è°ƒç”¨MCPæœåŠ¡è·å–tools
                    request = {
                        'jsonrpc': '2.0',
                        'id': f"req_{uuid.uuid4().hex[:16]}",
                        'method': 'tools/list',
                        'params': {}
                    }

                    async with aiohttp.ClientSession() as session:
                        async with session.post(mcp_server['url'], json=request, timeout=30) as response:
                            if response.status != 200:
                                logger.warning(
                                    f"âŒ Failed to get tools from {mcp_server['name']}: HTTP {response.status}")
                                continue

                            data = await response.json()
                            if 'error' in data:
                                logger.warning(
                                    f"âŒ MCP tools/list failed for {mcp_server['name']}: {data['error']['message']}")
                                continue

                            result = data.get('result', {})
                            server_tools = result.get('tools', []) if isinstance(result, dict) else []
                            logger.info(f"âœ… ä» {mcp_server['name']} è·å–åˆ° {len(server_tools)} ä¸ªå·¥å…·")

                            # è½¬æ¢ä¸ºOpenAIå·¥å…·æ ¼å¼
                            for tool in server_tools:
                                prefixed_name = f"{mcp_server['name']}_{tool['name']}"

                                openai_tool = {
                                    'type': 'function',
                                    'function': {
                                        'name': prefixed_name,
                                        'description': tool.get('description', ''),
                                        'parameters': tool.get('inputSchema', tool.get('parameters', {}))
                                    }
                                }

                                # å­˜å‚¨å…ƒæ•°æ®
                                self.tool_metadata[prefixed_name] = {
                                    'original_name': tool['name'],
                                    'server_name': mcp_server['name'],
                                    'server_url': mcp_server['url']
                                }

                                self.tools.append(openai_tool)
                                logger.info(f"  - æ·»åŠ å·¥å…·: {prefixed_name} ({tool.get('description', '')})")

                except Exception as e:
                    logger.error(f"âŒ Failed to get tools from MCP server {mcp_server['name']}: {e}")
                    continue

            logger.info(f"ğŸ› ï¸ å·¥å…·åˆ—è¡¨æ„å»ºå®Œæˆï¼Œæ€»è®¡ {len(self.tools)} ä¸ªå·¥å…·")

        except Exception as e:
            logger.error(f"âŒ buildTools failed: {e}")
            raise

    def get_tools(self) -> List[Dict[str, Any]]:
        """è·å–å·¥å…·åˆ—è¡¨"""
        return self.tools
