#!/usr/bin/env python3
"""
ä»»åŠ¡ç®¡ç†æœåŠ¡æ¨¡å—
æä¾›ä»»åŠ¡åˆ›å»ºã€æŸ¥è¯¢ã€çŠ¶æ€ç®¡ç†ç­‰æ ¸å¿ƒåŠŸèƒ½
"""

import asyncio
import json
import uuid
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any, AsyncGenerator
from dataclasses import dataclass, asdict

logger = logging.getLogger("task_manager_service")


@dataclass
class Task:
    """ä»»åŠ¡æ•°æ®æ¨¡å‹"""
    id: str
    task_title: str
    target_file: str
    operation: str
    specific_operations: str
    related: str
    dependencies: str
    session_id: str
    status: str = "pending"  # pending, in_progress, completed
    created_at: str = None
    updated_at: str = None
    viewed_count: int = 0  # è®°å½•ä»»åŠ¡è¢«æŸ¥çœ‹çš„æ¬¡æ•°
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now().isoformat()
        if self.updated_at is None:
            self.updated_at = datetime.now().isoformat()


@dataclass
class TaskExecution:
    """ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹æ•°æ®æ¨¡å‹"""
    task_id: str
    execution_process: str
    created_at: str = None
    updated_at: str = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now().isoformat()
        if self.updated_at is None:
            self.updated_at = datetime.now().isoformat()


class TaskManagerService:
    """ä»»åŠ¡ç®¡ç†æœåŠ¡ç±»
    
    è´Ÿè´£ä»»åŠ¡çš„åˆ›å»ºã€åŠ è½½ã€ä¿å­˜ã€æŸ¥è¯¢å’ŒçŠ¶æ€ç®¡ç†ã€‚
    é‡‡ç”¨å®Œå…¨æŒ‰éœ€åŠ è½½çš„æ–¹å¼ï¼Œæ¯æ¬¡æ“ä½œæ—¶ç›´æ¥ä»æ–‡ä»¶è¯»å–ï¼Œä¸ç»´æŠ¤å†…å­˜ç¼“å­˜ã€‚
    """
    
    def __init__(self, data_dir: str = "./task_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        self.auto_save = True
        
        # åˆ›å»ºæ‰§è¡Œè¿‡ç¨‹å­˜å‚¨ç›®å½•
        self.execution_dir = self.data_dir / "executions"
        self.execution_dir.mkdir(exist_ok=True)
        
        logger.info(f"TaskManagerService initialized with data dir: {self.data_dir.absolute()}")
    
    def _get_data_file_path(self, session_id: str) -> Path:
        """è·å–æ•°æ®æ–‡ä»¶è·¯å¾„"""
        filename = f"{session_id}.json"
        return self.data_dir / filename
    
    def _get_execution_file_path(self, task_id: str) -> Path:
        """è·å–ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹æ–‡ä»¶è·¯å¾„"""
        filename = f"{task_id}_execution.json"
        return self.execution_dir / filename
    

    
    def _load_tasks_from_file(self, file_path: Path) -> Dict[str, Task]:
        """ä»æŒ‡å®šæ–‡ä»¶åŠ è½½ä»»åŠ¡æ•°æ®"""
        tasks = {}
        if file_path.exists():
            try:
                # ä½¿ç”¨errors='replace'å‚æ•°å¤„ç†å¯èƒ½çš„ç¼–ç é”™è¯¯
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    data = json.load(f)
                    for task_data in data.get('tasks', []):
                        # ä¸ºæ—§æ•°æ®æä¾› viewed_count é»˜è®¤å€¼
                        if 'viewed_count' not in task_data:
                            task_data['viewed_count'] = 0
                        task = Task(**task_data)
                        tasks[task.id] = task

            except Exception as e:
                logger.error(f"åŠ è½½ä»»åŠ¡æ•°æ®å¤±è´¥ {file_path}: {e}")
        return tasks
    
    def _save_tasks_to_file(self, session_id: str, tasks: List[Task]):
        """ä¿å­˜ä»»åŠ¡æ•°æ®åˆ°æŒ‡å®šæ–‡ä»¶"""
        try:
            file_path = self._get_data_file_path(session_id)
            data = {
                'session_id': session_id,
                'tasks': [asdict(task) for task in tasks],
                'updated_at': datetime.now().isoformat()
            }
            with open(file_path, 'w', encoding='utf-8') as f:
                # è®¾ç½®ensure_ascii=Trueä»¥é¿å…UTF-8ç¼–ç é—®é¢˜
                json.dump(data, f, ensure_ascii=True, indent=2)
            logger.info(f"å·²ä¿å­˜ {len(tasks)} ä¸ªä»»åŠ¡åˆ° {file_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜ä»»åŠ¡æ•°æ®å¤±è´¥: {e}")
    
    def _save_task_execution(self, task_execution: TaskExecution):
        """ä¿å­˜ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹åˆ°æ–‡ä»¶"""
        try:
            file_path = self._get_execution_file_path(task_execution.task_id)
            data = asdict(task_execution)
            with open(file_path, 'w', encoding='utf-8') as f:
                # è®¾ç½®ensure_ascii=Trueä»¥é¿å…UTF-8ç¼–ç é—®é¢˜
                json.dump(data, f, ensure_ascii=True, indent=2)
            logger.info(f"å·²ä¿å­˜ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹åˆ° {file_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹å¤±è´¥: {e}")
    
    def _load_task_execution(self, task_id: str) -> Optional[TaskExecution]:
        """ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹"""
        file_path = self._get_execution_file_path(task_id)
        if file_path.exists():
            try:
                # ä½¿ç”¨errors='replace'å‚æ•°å¤„ç†å¯èƒ½çš„ç¼–ç é”™è¯¯
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    data = json.load(f)
                    return TaskExecution(**data)
            except Exception as e:
                logger.error(f"åŠ è½½ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹å¤±è´¥ {file_path}: {e}")
        return None
    
    def _get_task_by_id(self, task_id: str) -> Optional[Task]:
        """æ ¹æ®IDè·å–ä»»åŠ¡"""
        # éå†æ‰€æœ‰æ–‡ä»¶æŸ¥æ‰¾
        for data_file in self.data_dir.glob("*.json"):
            file_tasks = self._load_tasks_from_file(data_file)
            if task_id in file_tasks:
                return file_tasks[task_id]
        
        return None
    
    def _get_tasks_by_session(self, session_id: str) -> List[Task]:
        """è·å–æŒ‡å®šä¼šè¯çš„ä»»åŠ¡"""
        file_path = self._get_data_file_path(session_id)
        file_tasks = self._load_tasks_from_file(file_path)
        return list(file_tasks.values())
    

    
    async def create_tasks_stream(self, tasks_data: List[Dict[str, Any]], 
                                session_id: str) -> AsyncGenerator[str, None]:
        """åˆ›å»ºæˆ–ä¿®æ”¹ä»»åŠ¡ï¼ˆæµå¼è¾“å‡ºï¼‰
        
        å¦‚æœsession_idå¯¹åº”çš„æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥è¦†ç›–è¯¥æ–‡ä»¶ä¸­çš„ä»»åŠ¡
        """
        yield f"å¼€å§‹å¤„ç† {len(tasks_data)} ä¸ªä»»åŠ¡...\n"
        
        created_tasks = []
        errors = []
        
        # åŠ è½½ç°æœ‰ä»»åŠ¡ï¼ˆä»…ç”¨äºæ—¥å¿—è®°å½•ï¼‰
        file_path = self._get_data_file_path(session_id)
        existing_tasks = {}
        
        for i, task_data in enumerate(tasks_data):
            try:
                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = [
                    'task_title', 'target_file', 'operation', 
                    'specific_operations', 'related', 'dependencies'
                ]
                
                missing_fields = [field for field in required_fields if field not in task_data]
                if missing_fields:
                    errors.append({
                        'index': i,
                        'error': f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}"
                    })
                    continue
                
                # ç›´æ¥åˆ›å»ºæ–°ä»»åŠ¡ï¼Œä¸è€ƒè™‘ä¿®æ”¹ç°æœ‰ä»»åŠ¡
                # å¦‚æœæä¾›äº†task_idï¼Œåˆ™ä½¿ç”¨æä¾›çš„IDï¼Œå¦åˆ™ç”Ÿæˆæ–°ID
                task_id = task_data.get('task_id', str(uuid.uuid4()))
                # åˆ›å»ºæ–°ä»»åŠ¡
                task = Task(
                    id=task_id,
                    task_title=task_data['task_title'],
                    target_file=task_data['target_file'],
                    operation=task_data['operation'],
                    specific_operations=task_data['specific_operations'],
                    related=task_data['related'],
                    dependencies=task_data['dependencies'],
                    session_id=session_id,
                    status=task_data.get('status', 'pending')
                )
                
                created_tasks.append(task)
                yield f"[{i+1}/{len(tasks_data)}] åˆ›å»ºä»»åŠ¡: {task.task_title} (ID: {task_id})\n"
                
            except Exception as e:
                error_msg = f"[{i+1}/{len(tasks_data)}] å¤„ç†ä»»åŠ¡å¤±è´¥: {str(e)}\n"
                yield error_msg
                errors.append({
                    'index': i,
                    'error': str(e)
                })
        
        # ç›´æ¥ä¿å­˜åˆ°æ–‡ä»¶ï¼Œè¦†ç›–åŸæœ‰å†…å®¹
        tasks_to_save = created_tasks
        
        if tasks_to_save:
            self._save_tasks_to_file(session_id, tasks_to_save)
            yield f"\nâœ… æˆåŠŸåˆ›å»º {len(created_tasks)} ä¸ªä»»åŠ¡å¹¶ä¿å­˜åˆ°æ–‡ä»¶: {session_id}.json\n"
        
        if errors:
            yield f"âŒ å¤±è´¥ {len(errors)} ä¸ªä»»åŠ¡\n"
        
        yield f"\nğŸ“Š æ€»ç»“: æˆåŠŸåˆ›å»º {len(created_tasks)} ä¸ªä»»åŠ¡ï¼Œå¤±è´¥ {len(errors)} ä¸ª\n"
    
    async def get_next_executable_task_stream(self, session_id: str) -> AsyncGenerator[str, None]:
        """è·å–ä¸‹ä¸€ä¸ªå¯æ‰§è¡Œä»»åŠ¡çš„æµå¼ç‰ˆæœ¬ - å®Œå…¨æŒ‰éœ€åŠ è½½
        
        ä¿®æ”¹é€»è¾‘ï¼šå¦‚æœå·²æœ‰æ‰§è¡Œä¸­çš„ä»»åŠ¡ï¼Œåˆ™è¿”å›è¯¥ä»»åŠ¡è€Œä¸æ˜¯æŸ¥æ‰¾æ–°ä»»åŠ¡
        """
        yield "ğŸ” æ­£åœ¨æŸ¥æ‰¾å¯æ‰§è¡Œä»»åŠ¡...\n"
        
        # ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡
        file_path = self._get_data_file_path(session_id)
        if not file_path.exists():
            yield "âŒ æœªæ‰¾åˆ°ä»»åŠ¡æ–‡ä»¶\n"
            return
        
        tasks_dict = self._load_tasks_from_file(file_path)
        if not tasks_dict:
            yield "âŒ ä»»åŠ¡æ–‡ä»¶ä¸ºç©º\n"
            return
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰æ‰§è¡Œä¸­çš„ä»»åŠ¡
        in_progress_tasks = [task for task in tasks_dict.values() if task.status == 'in_progress']
        
        if in_progress_tasks:
            # å¦‚æœæœ‰æ‰§è¡Œä¸­çš„ä»»åŠ¡ï¼Œè¿”å›ç¬¬ä¸€ä¸ªï¼ˆæŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼‰
            current_task = min(in_progress_tasks, key=lambda t: t.created_at)
            
            # å¢åŠ æŸ¥çœ‹æ¬¡æ•°
            current_task.viewed_count += 1
            current_task.updated_at = datetime.now().isoformat()
            
            # ä¿å­˜æ›´æ–°åçš„ä»»åŠ¡æ•°æ®
            tasks_to_save = list(tasks_dict.values())
            self._save_tasks_to_file(session_id, tasks_to_save)
            
            # æ ¹æ®æŸ¥çœ‹æ¬¡æ•°ç»™å‡ºä¸åŒçš„æç¤º
            if current_task.viewed_count == 1:
                yield f"ğŸ”„ å‘ç°æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡: {current_task.task_title} (ID: {current_task.id})\n"
            else:
                yield f"ğŸ”„ è¿™ä¸ªä»»åŠ¡ä½ å·²ç»çœ‹è¿‡äº†ï¼ä»»åŠ¡: {current_task.task_title} (ID: {current_task.id})\n"
                yield f"ğŸ“Š æŸ¥çœ‹æ¬¡æ•°: {current_task.viewed_count} æ¬¡\n"
                yield f"âš ï¸ è¿™æ˜¯åŒä¸€ä¸ªä»»åŠ¡ï¼Œä½ ä¹‹å‰å·²ç»æŸ¥çœ‹è¿‡ {current_task.viewed_count - 1} æ¬¡\n"
            
            yield f"ğŸ“„ ç›®æ ‡æ–‡ä»¶: {current_task.target_file}\n"
            yield f"ğŸ”§ æ“ä½œç±»å‹: {current_task.operation}\n"
            yield f"ğŸ“ å…·ä½“æ“ä½œ: {current_task.specific_operations}\n"
            yield f"ğŸ”— ç›¸å…³ä¿¡æ¯: {current_task.related}\n"
            yield f"ğŸ“Š ä¾èµ–å…³ç³»: {current_task.dependencies}\n"
            yield f"âš ï¸ è¯·å…ˆå®Œæˆå½“å‰ä»»åŠ¡å†è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡\n"
            return
        
        # å¦‚æœæ²¡æœ‰æ‰§è¡Œä¸­çš„ä»»åŠ¡ï¼ŒæŸ¥æ‰¾å¯æ‰§è¡Œä»»åŠ¡
        executable_tasks = []
        for task in tasks_dict.values():
            if task.status == 'pending':
                # æ£€æŸ¥ä¾èµ–æ˜¯å¦å·²å®Œæˆï¼ˆcompletedæˆ–dev_completedéƒ½ç®—å®Œæˆï¼‰
                dependencies_met = True
                if task.dependencies and task.dependencies != "æ— ":
                    for dep_id in task.dependencies.split(','):
                        dep_id = dep_id.strip()
                        if dep_id and dep_id in tasks_dict and tasks_dict[dep_id].status not in ['completed', 'dev_completed']:
                            dependencies_met = False
                            break
                
                if dependencies_met:
                    executable_tasks.append(task)
        
        if not executable_tasks:
            yield "âŒ æ²¡æœ‰æ‰¾åˆ°å¯æ‰§è¡Œçš„ä»»åŠ¡\n"
            return
        
        # è¿”å›ç¬¬ä¸€ä¸ªå¯æ‰§è¡Œä»»åŠ¡ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼‰
        next_task = min(executable_tasks, key=lambda t: t.created_at)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        next_task.status = 'in_progress'
        next_task.updated_at = datetime.now().isoformat()
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        tasks_to_save = list(tasks_dict.values())
        self._save_tasks_to_file(session_id, tasks_to_save)
        
        yield f"âœ… æ‰¾åˆ°æ–°çš„å¯æ‰§è¡Œä»»åŠ¡: {next_task.task_title} (ID: {next_task.id})\n"
        yield f"ğŸ“„ ç›®æ ‡æ–‡ä»¶: {next_task.target_file}\n"
        yield f"ğŸ”§ æ“ä½œç±»å‹: {next_task.operation}\n"
        yield f"ğŸ“ å…·ä½“æ“ä½œ: {next_task.specific_operations}\n"
        yield f"ğŸ”— ç›¸å…³ä¿¡æ¯: {next_task.related}\n"
        yield f"ğŸ“Š ä¾èµ–å…³ç³»: {next_task.dependencies}\n"
        yield f"â–¶ï¸ ä»»åŠ¡å·²æ ‡è®°ä¸ºè¿›è¡Œä¸­\n"
    
    async def complete_task_stream(self, task_id: str) -> AsyncGenerator[str, None]:
        """å®Œæˆä»»åŠ¡çš„æµå¼ç‰ˆæœ¬ - å®Œå…¨æŒ‰éœ€åŠ è½½"""
        yield f"ğŸ” æ­£åœ¨æŸ¥æ‰¾ä»»åŠ¡ {task_id}...\n"
        
        task_found = None
        session_id = None
        file_path = None
        
        # éå†æ‰€æœ‰ä»»åŠ¡æ–‡ä»¶æŸ¥æ‰¾ä»»åŠ¡
        for file in self.data_dir.glob("*.json"):
            try:
                tasks_dict = self._load_tasks_from_file(file)
                if task_id in tasks_dict:
                    task_found = tasks_dict[task_id]
                    session_id = file.stem
                    file_path = file
                    break
            except Exception:
                continue
        
        if not task_found:
            yield f"âŒ ä»»åŠ¡ {task_id} ä¸å­˜åœ¨\n"
            return
        
        yield f"ğŸ“‹ æ‰¾åˆ°ä»»åŠ¡: {task_found.task_title}\n"
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task_found.status = 'completed'
        task_found.updated_at = datetime.now().isoformat()
        
        # é‡æ–°åŠ è½½æ‰€æœ‰ä»»åŠ¡å¹¶ä¿å­˜
        tasks_dict = self._load_tasks_from_file(file_path)
        tasks_dict[task_id] = task_found
        tasks_to_save = list(tasks_dict.values())
        
        self._save_tasks_to_file(session_id, tasks_to_save)
        yield f"âœ… ä»»åŠ¡ '{task_found.task_title}' å·²æ ‡è®°ä¸ºå®Œæˆ\n"
        yield f"ğŸ’¾ å·²ä¿å­˜åˆ°æ–‡ä»¶: {session_id}.json\n"
    
    async def get_task_stats_stream(self, session_id: str) -> AsyncGenerator[str, None]:
        """è·å–ä»»åŠ¡ç»Ÿè®¡çš„æµå¼ç‰ˆæœ¬ - å®Œå…¨æŒ‰éœ€åŠ è½½"""
        yield "ğŸ“Š æ­£åœ¨ç»Ÿè®¡ä»»åŠ¡ä¿¡æ¯...\n"
        
        # ä»æŒ‡å®šä¼šè¯æ–‡ä»¶åŠ è½½ä»»åŠ¡
        file_path = self._get_data_file_path(session_id)
        if not file_path.exists():
            yield f"âŒ ä¼šè¯ {session_id} çš„ä»»åŠ¡æ–‡ä»¶ä¸å­˜åœ¨\n"
            return
        
        tasks_dict = self._load_tasks_from_file(file_path)
        all_tasks = list(tasks_dict.values())
        
        scope = f"ä¼šè¯ {session_id}"
        yield f"ğŸ” ç»Ÿè®¡èŒƒå›´: {scope}\n"
        
        if not all_tasks:
            yield f"â„¹ï¸ {scope}æ²¡æœ‰ä»»åŠ¡\n"
            return
        
        stats = {
            'total': len(all_tasks),
            'pending': len([t for t in all_tasks if t.status == 'pending']),
            'in_progress': len([t for t in all_tasks if t.status == 'in_progress']),
            'dev_completed': len([t for t in all_tasks if t.status == 'dev_completed']),
            'completed': len([t for t in all_tasks if t.status == 'completed'])
        }
        
        yield f"ğŸ“ˆ {scope}ä»»åŠ¡ç»Ÿè®¡:\n"
        yield f"  ğŸ“‹ æ€»è®¡: {stats['total']} ä¸ª\n"
        yield f"  â³ å¾…æ‰§è¡Œ: {stats['pending']} ä¸ª\n"
        yield f"  ğŸ”„ è¿›è¡Œä¸­: {stats['in_progress']} ä¸ª\n"
        yield f"  ğŸš€ å¼€å‘å®Œæˆ: {stats['dev_completed']} ä¸ª\n"
        yield f"  âœ… å·²å®Œæˆ: {stats['completed']} ä¸ª\n"
        
        if all_tasks:
            yield "\nğŸ“ ä»»åŠ¡åˆ—è¡¨:\n"
            for i, task in enumerate(all_tasks, 1):
                status_emoji = {
                    'pending': 'â³', 
                    'in_progress': 'ğŸ”„', 
                    'dev_completed': 'ğŸš€',
                    'completed': 'âœ…'
                }.get(task.status, 'â“')
                yield f"  {i}. {status_emoji} {task.task_title} (ID: {task.id})\n"
    

    

    
    def update_data_dir(self, new_data_dir: str) -> Dict[str, Any]:
        """æ›´æ–°æ•°æ®ç›®å½•"""
        try:
            old_dir = self.data_dir
            self.data_dir = Path(new_data_dir)
            self.data_dir.mkdir(exist_ok=True)
            
            # æ›´æ–°æ‰§è¡Œè¿‡ç¨‹å­˜å‚¨ç›®å½•
            self.execution_dir = self.data_dir / "executions"
            self.execution_dir.mkdir(exist_ok=True)
            
            logger.info(f"æ•°æ®ç›®å½•å·²æ›´æ–°: {old_dir} -> {self.data_dir}")
            return {
                'success': True,
                'message': f'æ•°æ®ç›®å½•å·²æ›´æ–°ä¸º: {self.data_dir.absolute()}',
                'old_dir': str(old_dir),
                'new_dir': str(self.data_dir)
            }
        except Exception as e:
            logger.error(f"æ›´æ–°æ•°æ®ç›®å½•å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    

    
    def set_auto_save(self, auto_save: bool):
        """è®¾ç½®è‡ªåŠ¨ä¿å­˜"""
        self.auto_save = auto_save
    
    async def get_current_executing_task_stream(self, session_id: str) -> AsyncGenerator[str, None]:
        """è·å–å½“å‰æ­£åœ¨æ‰§è¡Œæˆ–å¼€å‘å®Œæˆçš„ä»»åŠ¡çš„æµå¼ç‰ˆæœ¬
        
        Args:
            session_id: ä¼šè¯ID
            
        Yields:
            str: æµå¼è¾“å‡ºçš„ä»»åŠ¡ä¿¡æ¯
        """
        yield "ğŸ” æ­£åœ¨æŸ¥æ‰¾å½“å‰æ‰§è¡Œä¸­æˆ–å¼€å‘å®Œæˆçš„ä»»åŠ¡...\n"
        
        # ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡
        file_path = self._get_data_file_path(session_id)
        if not file_path.exists():
            yield "âŒ æœªæ‰¾åˆ°ä»»åŠ¡æ–‡ä»¶\n"
            return
        
        tasks_dict = self._load_tasks_from_file(file_path)
        if not tasks_dict:
            yield "âŒ ä»»åŠ¡æ–‡ä»¶ä¸ºç©º\n"
            return
        
        # æŸ¥æ‰¾æ‰§è¡Œä¸­æˆ–å¼€å‘å®Œæˆçš„ä»»åŠ¡
        active_tasks = [task for task in tasks_dict.values() if task.status in ['in_progress', 'dev_completed']]
        
        if not active_tasks:
            yield "â„¹ï¸ å½“å‰æ²¡æœ‰æ­£åœ¨æ‰§è¡Œæˆ–å¼€å‘å®Œæˆçš„ä»»åŠ¡\n"
            return
        
        # ä¼˜å…ˆè¿”å›in_progressä»»åŠ¡ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›æœ€æ–°çš„dev_completedä»»åŠ¡
        in_progress_tasks = [task for task in active_tasks if task.status == 'in_progress']
        dev_completed_tasks = [task for task in active_tasks if task.status == 'dev_completed']
        
        if in_progress_tasks:
            current_task = min(in_progress_tasks, key=lambda t: t.created_at)
            status_desc = "æ‰§è¡Œä¸­"
        else:
            current_task = max(dev_completed_tasks, key=lambda t: t.updated_at)
            status_desc = "å¼€å‘å®Œæˆ"
        
        yield f"âœ… æ‰¾åˆ°å½“å‰{status_desc}çš„ä»»åŠ¡\n"
        yield f"ğŸ“‹ ä»»åŠ¡æ ‡é¢˜: {current_task.task_title}\n"
        yield f"ğŸ†” ä»»åŠ¡ID: {current_task.id}\n"
        yield f"ğŸ“Š ä»»åŠ¡çŠ¶æ€: {current_task.status}\n"
        yield f"ğŸ“„ ç›®æ ‡æ–‡ä»¶: {current_task.target_file}\n"
        yield f"ğŸ”§ æ“ä½œç±»å‹: {current_task.operation}\n"
        yield f"ğŸ“ å…·ä½“æ“ä½œ: {current_task.specific_operations}\n"
        yield f"ğŸ”— ç›¸å…³ä¿¡æ¯: {current_task.related}\n"
        yield f"ğŸ“Š ä¾èµ–å…³ç³»: {current_task.dependencies}\n"
        yield f"ğŸ“… åˆ›å»ºæ—¶é—´: {current_task.created_at}\n"
        yield f"ğŸ”„ æ›´æ–°æ—¶é—´: {current_task.updated_at}\n"
        yield f"ğŸ‘€ æŸ¥çœ‹æ¬¡æ•°: {current_task.viewed_count}\n"
        
        # æŸ¥è¯¢ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹
        task_execution = self._load_task_execution(current_task.id)
        if task_execution:
            yield f"\nğŸ“‹ æ‰§è¡Œè¿‡ç¨‹ä¿¡æ¯:\n"
            yield f"ğŸ’¾ ä¿å­˜æ—¶é—´: {task_execution.created_at}\n"
            yield f"ğŸ”„ æ›´æ–°æ—¶é—´: {task_execution.updated_at}\n"
            yield f"ğŸ“ æ‰§è¡Œè¿‡ç¨‹:\n{task_execution.execution_process}\n"
        else:
            yield f"\nâš ï¸ è¯¥ä»»åŠ¡æš‚æ— æ‰§è¡Œè¿‡ç¨‹è®°å½•\n"
        
        if len(active_tasks) > 1:
            yield f"âš ï¸ æ³¨æ„: å‘ç° {len(active_tasks)} ä¸ªæ´»è·ƒä»»åŠ¡ï¼ˆ{len(in_progress_tasks)}ä¸ªæ‰§è¡Œä¸­ï¼Œ{len(dev_completed_tasks)}ä¸ªå¼€å‘å®Œæˆï¼‰ï¼Œæ˜¾ç¤ºä¼˜å…ˆçº§æœ€é«˜çš„ä»»åŠ¡\n"
    
    async def save_task_execution_stream(self, task_id: str, execution_process: str) -> AsyncGenerator[str, None]:
        """ä¿å­˜ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹çš„æµå¼ç‰ˆæœ¬ï¼Œå¹¶å°†ä»»åŠ¡çŠ¶æ€æ”¹ä¸ºdev_completed"""
        yield f"ğŸ’¾ æ­£åœ¨ä¿å­˜ä»»åŠ¡ {task_id} çš„æ‰§è¡Œè¿‡ç¨‹...\n"
        
        # éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = self._get_task_by_id(task_id)
        if not task:
            yield f"âŒ ä»»åŠ¡ {task_id} ä¸å­˜åœ¨\n"
            return
        
        # åˆ›å»ºä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹å¯¹è±¡
        task_execution = TaskExecution(
            task_id=task_id,
            execution_process=execution_process
        )
        
        # ä¿å­˜æ‰§è¡Œè¿‡ç¨‹åˆ°æ–‡ä»¶
        self._save_task_execution(task_execution)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºdev_completed
        original_status = task.status
        task.status = 'dev_completed'
        task.updated_at = datetime.now().isoformat()
        
        # ä¿å­˜æ›´æ–°åçš„ä»»åŠ¡æ•°æ®
        session_id = task.session_id
        file_path = self._get_data_file_path(session_id)
        tasks_dict = self._load_tasks_from_file(file_path)
        tasks_dict[task_id] = task
        tasks_to_save = list(tasks_dict.values())
        self._save_tasks_to_file(session_id, tasks_to_save)
        
        yield f"âœ… ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹å·²ä¿å­˜\n"
        yield f"ğŸ“‹ ä»»åŠ¡æ ‡é¢˜: {task.task_title}\n"
        yield f"ğŸ†” ä»»åŠ¡ID: {task_id}\n"
        yield f"ğŸ“ æ‰§è¡Œè¿‡ç¨‹é•¿åº¦: {len(execution_process)} å­—ç¬¦\n"
        yield f"ğŸ’¾ ä¿å­˜æ—¶é—´: {task_execution.created_at}\n"
        yield f"ğŸ”„ ä»»åŠ¡çŠ¶æ€: {original_status} â†’ dev_completed\n"