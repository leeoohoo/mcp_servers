#!/usr/bin/env python3
"""
ä»»åŠ¡ç®¡ç†å™¨ MCP æœåŠ¡å™¨ï¼ˆæ³¨è§£ç‰ˆæœ¬ï¼‰
åŸºäº EnhancedMCPServer å’Œè£…é¥°å™¨ç³»ç»Ÿçš„ä»»åŠ¡ç®¡ç†æœåŠ¡å™¨

ä¸»è¦åŠŸèƒ½:
1. create_tasks - åˆ›å»ºå•ä¸ªæˆ–æ‰¹é‡ä»»åŠ¡ï¼ˆæµå¼è¾“å‡ºï¼‰
2. get_next_executable_task - è·å–ä¸‹ä¸€ä¸ªå¯æ‰§è¡Œä»»åŠ¡ï¼ˆæµå¼è¾“å‡ºï¼‰
3. complete_task - æ ‡è®°ä»»åŠ¡ä¸ºå·²å®Œæˆï¼ˆæµå¼è¾“å‡ºï¼‰
4. get_task_stats - è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯ï¼ˆæµå¼è¾“å‡ºï¼‰
5. query_tasks - æ ¹æ®æ¡ä»¶æŸ¥è¯¢ä»»åŠ¡ï¼ˆæµå¼è¾“å‡ºï¼‰
6. get_current_executing_task - è·å–å½“å‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆæµå¼è¾“å‡ºï¼‰

æ¶æ„ä¼˜åŒ–:
- åˆ†ç¦»ä¸šåŠ¡é€»è¾‘åˆ° TaskManagerService
- å®ç°æŒ‰éœ€åŠ è½½ï¼Œé¿å…å†…å­˜è¿‡è½½
- ä½¿ç”¨ LRU ç¼“å­˜æœºåˆ¶
- æ”¯æŒé…ç½®å‚æ•°åŠ¨æ€è°ƒæ•´
"""

import logging
from typing import List, Optional, Dict, Any, AsyncGenerator
from typing_extensions import Annotated

# å¯¼å…¥ä»»åŠ¡ç®¡ç†æœåŠ¡
from task_manager_service import TaskManagerService


from mcp_framework.core import EnhancedMCPServer

# å¯¼å…¥è£…é¥°å™¨
from mcp_framework.core.decorators import (
    Required as R,
    Optional as O,

)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("task_manager_server")


class TaskManagerServer(EnhancedMCPServer):
    """åŸºäºæ³¨è§£è£…é¥°å™¨çš„ä»»åŠ¡ç®¡ç†å™¨MCPæœåŠ¡å™¨"""

    def __init__(self):
        super().__init__(
            name="task-manager-server",
            version="2.0.0",
            description="ä»»åŠ¡ç®¡ç†å™¨MCPæœåŠ¡å™¨ï¼ŒåŸºäºæ³¨è§£è£…é¥°å™¨ç³»ç»Ÿæä¾›æµå¼ä»»åŠ¡ç®¡ç†åŠŸèƒ½"
        )
        # åœ¨æ„é€ å‡½æ•°ä¸­å°±åˆå§‹åŒ–æœåŠ¡ï¼Œä½¿ç”¨é»˜è®¤å€¼
        self.task_manager_service = TaskManagerService()
        logger.info("TaskManagerServer initialized")

    async def initialize(self) -> None:
        """åˆå§‹åŒ–æœåŠ¡å™¨ï¼ˆå®ç°åŸºç±»æŠ½è±¡æ–¹æ³•ï¼‰"""
        
        # è°ƒç”¨åŸºç±»çš„åˆå§‹åŒ–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(super(), 'initialize'):
            await super().initialize()
        
        # è·å–é…ç½®å‚æ•°å¹¶é‡æ–°åˆå§‹åŒ–æœåŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        try:
            data_dir = self.get_config_value("data_dir")
            if data_dir and data_dir.strip():
                # å¦‚æœé…ç½®äº†æ•°æ®ç›®å½•ï¼Œé‡æ–°åˆå§‹åŒ–æœåŠ¡
                self.task_manager_service = TaskManagerService(data_dir.strip())
                logger.info(f"Using configured data directory: {data_dir}")
            else:
                # ä½¿ç”¨é»˜è®¤çš„æ•°æ®ç›®å½•
                logger.info("Using default data directory: task_data")
        except Exception as e:
            logger.warning(f"Failed to get config, using default: {e}")
        
        # ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–
        if self.task_manager_service is None:
            self.task_manager_service = TaskManagerService()
            logger.info("Initialized task manager service with defaults")
    
    @property
    def setup_server_params(self):
        """è®¾ç½®æœåŠ¡å™¨å‚æ•°"""
        
        @self.decorators.server_param
        def data_dir(
            self,
            value: Annotated[str, R("Data directory for storing task files")]
        ) -> str:
            """Data directory for task storage
            
            Specifies the directory where task data files will be stored.
            Each conversation-request pair will have its own JSON file.
            
            Default: './task_data'
            """
            return value
        

        @self.decorators.server_param
        def auto_save(
            self,
            value: Annotated[bool, R("Whether to automatically save tasks to disk")]
        ) -> bool:
            """Auto-save tasks to disk
            
            When enabled, tasks are automatically saved to disk after creation
            or status updates. Disable for better performance if manual saves
            are preferred.
            
            Default: True
            """
            return value
    
    async def on_config_updated(self, config_key: str, new_value: Any) -> None:
        """é…ç½®æ›´æ–°å›è°ƒæ–¹æ³•"""
        if config_key == "data_dir":
            try:
                # ä½¿ç”¨æ–°çš„åŠ¨æ€æ›´æ–°æ–¹æ³•
                if self.task_manager_service:
                    data_dir = str(new_value).strip() if new_value else ""
                    result = self.task_manager_service.update_data_dir(data_dir)
                    
                    if result.get("success"):
                        logger.info(f"Config updated successfully: {result['message']}")
                    else:
                        logger.error(f"Failed to update data directory: {result.get('error', 'Unknown error')}")
                else:
                    # å¦‚æœæœåŠ¡æœªåˆå§‹åŒ–ï¼Œåˆ›å»ºæ–°æœåŠ¡
                    data_dir = str(new_value).strip() if new_value else "task_data"
                    self.task_manager_service = TaskManagerService(data_dir)
                    logger.info(f"Created new task manager service with data dir: {data_dir}")
            except Exception as e:
                logger.error(f"Error updating config {config_key}: {e}")
        elif config_key == "auto_save":
            try:
                if self.task_manager_service and hasattr(self.task_manager_service, 'set_auto_save'):
                    self.task_manager_service.set_auto_save(bool(new_value))
                    logger.info(f"Auto save updated to: {new_value}")
            except Exception as e:
                logger.error(f"Error updating auto save: {e}")
    
    def _normalize_stream_chunk(self, chunk: str) -> str:
        """æ ‡å‡†åŒ–æµå¼è¾“å‡ºå—"""
        if not chunk:
            return ""
        
        # ç¡®ä¿ä»¥æ¢è¡Œç¬¦ç»“å°¾
        if not chunk.endswith('\n'):
            chunk += '\n'
        
        return chunk

    @property
    def setup_tools(self):
        """è®¾ç½®å·¥å…·è£…é¥°å™¨"""

        @self.streaming_tool(description="ğŸ“ **Task Creator** - Creates single or batch tasks with comprehensive validation.\n" +
                         "\nâœ¨ **Features**: Batch task creation, Field validation, Progress tracking, File-based persistence, Direct file overwrite\n" +
                         "ğŸ¯ **Use Cases**: Project planning, Task breakdown, Workflow management, Team coordination\n" +
                         "\nğŸ“‹ **Required Parameters**:\n" +
                         "â€¢ tasks (list): List of task objects, each containing the required fields below\n" +
                         "â€¢ session_id (string): Session ID for task grouping and isolation (if file exists, it will be overwritten)\n" +
                         "\nğŸ“ **Task Object Fields** (each task object must contain):\n" +
                         "â€¢ task_title (string): Task title, concise description of the task\n" +
                         "â€¢ target_file (string): Target file path or name\n" +
                         "â€¢ operation (string): Operation type (e.g., create, update, delete, analyze)\n" +
                         "â€¢ specific_operations (string): Detailed operation description\n" +
                         "â€¢ related (string): Related information or context\n" +
                         "â€¢ dependencies (string): Dependent task IDs, comma-separated, empty string if no dependencies\n" +
                         "â€¢ task_id (string, optional): Custom task ID, if not provided a UUID will be generated\n" +
                         "\nğŸ“„ **Request Example**:\n" +
                         "{\n" +
                         "  \"tasks\": [\n" +
                         "    {\n" +
                         "      \"task_title\": \"Create User Model\",\n" +
                         "      \"target_file\": \"models/user.py\",\n" +
                         "      \"operation\": \"create\",\n" +
                         "      \"specific_operations\": \"Define User class with id, name, email fields\",\n" +
                         "      \"related\": \"Core model for user management system\",\n" +
                         "      \"dependencies\": \"\"\n" +
                         "    },\n" +
                         "    {\n" +
                         "      \"task_title\": \"Create User Service\",\n" +
                         "      \"target_file\": \"services/user_service.py\",\n" +
                         "      \"operation\": \"create\",\n" +
                         "      \"specific_operations\": \"Implement user CRUD operations\",\n" +
                         "      \"related\": \"Depends on user model\",\n" +
                         "      \"dependencies\": \"task_id_1\"\n" +
                         "    },\n" +
                         "    {\n" +
                         "      \"task_id\": \"custom_task_id_2\",\n" +
                         "      \"task_title\": \"Create User Model\",\n" +
                         "      \"target_file\": \"models/user.py\",\n" +
                         "      \"operation\": \"update\",\n" +
                         "      \"specific_operations\": \"Add address and phone fields to User class\",\n" +
                         "      \"related\": \"Enhanced user model with contact information\",\n" +
                         "      \"dependencies\": \"\"\n" +
                         "    }\n" +
                         "  ],\n" +
                         "  \"session_id\": \"session_123\"\n" +
                         "}\n" +
                         "\nâš ï¸ **Output Format**: Streams creation progress and saves to session_id.json (overwrites if exists)\n" +
                         "ğŸ’¡ Perfect for organizing complex projects with dependent tasks and clear tracking.", role="planner")
        async def create_tasks(
                tasks: Annotated[List[Dict[str, Any]], R("List of tasks to create, each containing required fields")],
                session_id: Annotated[str, R("Session ID for task grouping and isolation (if file exists, it will be overwritten)")]
        ) -> AsyncGenerator[str, None]:
            """Creates single or batch tasks with validation and progress tracking, overwrites existing file if session_id exists"""
            async for chunk in self.task_manager_service.create_tasks_stream(tasks, session_id):
                yield self._normalize_stream_chunk(chunk)
        
        @self.streaming_tool(description="â–¶ï¸ **Task Executor** - Returns current in-progress task or finds next executable task.\n" +
                         "âœ¨ Features: In-progress task tracking, Dependency resolution, Status checking, Priority ordering\n" +
                         "ğŸ¯ Use Cases: Workflow execution, Task scheduling, Dependency management, Progress tracking\n" +
                         "ğŸ“‹ **Required Parameters**: session_id (parameter is mandatory)\n" +
                         "âš ï¸ **Output Format**: Streams current in-progress task or next executable task details\n" +
                         "ğŸ’¡ If a task is already in progress, returns that task. Otherwise finds next executable task.", role="development")
        async def get_next_executable_task(
                session_id: Annotated[str, R("Session ID for task grouping and isolation")]
        ) -> AsyncGenerator[str, None]:
            """Finds the next executable task based on dependencies and status"""
            async for chunk in self.task_manager_service.get_next_executable_task_stream(session_id):
                yield self._normalize_stream_chunk(chunk)
        
        @self.streaming_tool(description="âœ… **Task Completer** - Marks tasks as completed with validation and persistence.\n" +
                         "âœ¨ Features: Task validation, Status updates, File persistence, Progress tracking\n" +
                         "ğŸ¯ Use Cases: Task completion, Workflow progression, Status management, Record keeping\n" +
                         "ğŸ“‹ **Required Parameters**: task_id (parameter is mandatory)\n" +
                         "âš ï¸ **Output Format**: Streams completion status and saves to corresponding JSON file\n" +
                         "ğŸ’¡ Automatically updates task status and maintains data consistency.", role="inspector")
        async def complete_task(
                task_id: Annotated[str, R("Task ID to mark as completed")]
        ) -> AsyncGenerator[str, None]:
            """Marks a task as completed with validation and persistence"""
            async for chunk in self.task_manager_service.complete_task_stream(task_id):
                yield self._normalize_stream_chunk(chunk)
        
        @self.streaming_tool(description="ğŸ“Š **Task Statistics** - Provides comprehensive task analytics and metrics.\n" +
                         "âœ¨ Features: Status breakdown, Progress tracking, Session filtering, Real-time stats\n" +
                         "ğŸ¯ Use Cases: Project monitoring, Progress reporting, Performance analysis, Team oversight\n" +
                         "ğŸ“‹ **Required Parameters**: session_id (parameter is mandatory)\n" +
                         "âš ï¸ **Output Format**: Streams detailed statistics and task breakdowns\n" +
                         "ğŸ’¡ Perfect for monitoring project progress and team productivity.", role="manager")
        async def get_task_stats(
                session_id: Annotated[str, R("Session ID for task grouping and isolation")]
        ) -> AsyncGenerator[str, None]:
            """Provides comprehensive task analytics and metrics"""
            async for chunk in self.task_manager_service.get_task_stats_stream(session_id):
                yield self._normalize_stream_chunk(chunk)
        

        @self.streaming_tool(description="ğŸ” **Current Task Inspector** - Retrieves the currently executing task for inspection.\n" +
                         "âœ¨ Features: Current task tracking, Detailed task information, Execution status monitoring, Execution process viewing\n" +
                         "ğŸ¯ Use Cases: Task inspection, Progress monitoring, Current status checking, Quality assurance\n" +
                         "ğŸ“‹ **Required Parameters**: session_id (parameter is mandatory)\n" +
                         "âš ï¸ **Output Format**: Streams current executing task details with comprehensive information including execution process\n" +
                         "ğŸ’¡ Perfect for inspectors to check what task is currently being executed and view saved execution process.", role="inspector")
        async def get_current_executing_task(
                session_id: Annotated[str, R("Session ID for task grouping and isolation")]
        ) -> AsyncGenerator[str, None]:
            """Retrieves the currently executing task for inspection"""
            async for chunk in self.task_manager_service.get_current_executing_task_stream(session_id):
                yield self._normalize_stream_chunk(chunk)
        
        @self.streaming_tool(description="ğŸ’¾ **Task Execution Recorder** - Saves task execution process for development tracking.\n" +
                         "âœ¨ Features: Execution process storage, Task validation, File-based persistence, Progress tracking\n" +
                         "ğŸ¯ Use Cases: Development documentation, Process recording, Task completion tracking, Quality assurance\n" +
                         "ğŸ“‹ **Required Parameters**: task_id, execution_process (BOTH parameters are mandatory)\n" +
                         "âš ï¸ **Output Format**: Streams save confirmation and creates individual execution file per task\n" +
                         "ğŸ’¡ Perfect for developers to record their execution process after completing tasks.", role="development")
        async def save_task_execution(
                task_id: Annotated[str, R("Task ID to save execution process for")],
                execution_process: Annotated[str, R("Detailed execution process description")]
        ) -> AsyncGenerator[str, None]:
            """Saves task execution process for development tracking"""
            async for chunk in self.task_manager_service.save_task_execution_stream(task_id, execution_process):
                yield self._normalize_stream_chunk(chunk)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # å¯¼å…¥ MCP æ¡†æ¶å¯åŠ¨å™¨
        from mcp_framework import run_server_main
        
        # åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
        server = TaskManagerServer()
        
        # ä½¿ç”¨ MCP æ¡†æ¶å¯åŠ¨å™¨å¯åŠ¨æœåŠ¡å™¨
        run_server_main(
            server_instance=server,
            server_name="Task Manager MCP Server",
            default_port=8004,
            default_host="localhost",
            required_dependencies=[]
        )
    except Exception as e:
        logger.error(f"å¯åŠ¨æœåŠ¡å™¨å¤±è´¥: {e}")
        import sys
        sys.exit(1)


# å¯åŠ¨æœåŠ¡å™¨
if __name__ == "__main__":
    main()